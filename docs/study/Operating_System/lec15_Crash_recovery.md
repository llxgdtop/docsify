## 课前内容

日志区域包括了一个日志头块**logheader**，以及一系列的日志块，它们是更新后的缓存块的副本，也称为**logged blocks**。磁盘上的logheader包含了一个数组，用于记录每个logged block要写入的目的磁盘位置（即扇区号），以及对于logged blocks的计数n。这个计数n要么为0，代表日志区中没有事务；要么不为0，代表日志区包含有一个已成功提交的事务，且该事务要处理的日志块数量是n（不会说我要处理的日志块是5，但处理到2时断电了，那就认为是0而不是2，说明这个是原子性的，要么是0要么是n）。xv6在将所有logged blocks写入日志之后，就写入logheader，一旦写入磁盘成功，就代表该事务已被成功提交。然后在加检查点完成之后，对计数n清零。若崩溃发生在事务提交以前，logheader计数n=0；若发生在事务提交之后，logheader计数n不为0。

 

为了提高文件系统操作的并发性，如果有多个FS系统调用并发执行，只要日志区域的空间足够，日志系统就将收集来自多个FS系统调用的多个写磁盘操作，并将它们组织成一个事务。为了避免将一次FS系统调用拆散到多个事务中，仅在当前没有FS系统调用执行时，日志系统才提交事务。这种思想称为group commit，可以减少磁盘操作数。（xv6没有这种功能，因为它是数据日志）

 

没有FS系统调用能够向磁盘写入数量超过日志空间大小的缓存块。这一点对于大多数FS系统调用来说都是满足的，但是有两个FS系统调用例外，它们可能需要更新大量的磁盘块，那就是write和unlink调用。对于一个大文件的写入，可能需要写入数量远比日志空间大小大得多的缓存块；而unlink一个大的文件，则可能需要更新大量的位图块和文件的inode。对此xv6的处理是，将一个很大的write，拆分成多个符合大小要求的写请求；而对于unlink，在xv6的情况下并不会引起问题，因为xv6只有一个位图块。然后是，日志空间大小的限制，如果日志区域中还有旧的事务存留，且剩余空间不能满足一个新的FS系统调用请求，那么新的FS系统调用将会阻塞，直到日志区域中腾出足够的空间。

与日志层相关的主要上层接口有三个：begin_op、log_write和end_op

begin_op();

*// ...*

bp **=** bread(...);   *// read out bp*

bp**->**data[...] **=** ...; *// modify bp->data[]*

log_write(bp);    *// bp has been modified, so put it in log*

brelse(bp);      *// release bp*

*// ...*

end_op();

如上是一个大致的fs系统调用

**先看struct logheader**和**struct log**。logheader中，包含前面提到的计数n，以及一个数组block，数组指示了每个logged blocks要写入的目标磁盘位置。log则由一把锁、一个logheader和一系列标志位组成。start记录日志区域开始的磁盘位置，size是日志区域的总块数，outstanding表示当前有多少FS系统调用正在使用日志系统（在beginop中会加一，在endop中减一，等于0说明没有正在执行的fs syscall，若在endop中发现该计数为0则可以提交log），committing表示日志系统是否正在加检查点。

 

**值得一提的是，logheader是真正的on-disk data structure，日志区域中的logheader就是该数据结构；而log只是在内存中维护的一份数据结构，日志区域中的logged blocks只存放更新后的缓存块副本。**

 

首先是**begin_op**，它应该在每个FS系统调用开始之前被调用。begin_op等待日志系统加检查点的完成，并且发现有足够的空间容纳新的事务，那么才能开始处理这次FS系统调用。当前，日志系统中已经被使用的空间是log.outstanding * MAXOPBLOCKS。通过增加log.outstanding计数，不仅表示该FS调用现在占用日志系统的部分空间，还防止日志系统在FS调用的中途就开始提交事务。最后，xv6的每次FS系统调用最多只会提交数量为MAXOPBLOCKS的日志块，因此它保守地假设每个FS调用都需要这么多空间。（outstanding表示的是当前正在并发执行的文件系统操作的个数，MAXOPBLOCKS定义了一个操作最大可能涉及的block数量。在begin_op中，只要log空间还足够，就可以一直增加并发执行的文件系统操作。所以XV6是通过设定了MAXOPBLOCKS，再间接的限定支持的并发文件系统操作的个数）

 

接着是**log_write**。我们在前面的框架中，读取了缓存块并且更新，然后再写回磁盘上，如果我们要使用日志系统，那么就应该使用日志系统提供的接口log_write，而不是Buffer Cache提供的接口bwrite。log_write先检查写日志操作是否合法，然后记录下每个日志块要写入的磁盘位置，增加logheader的计数n，还要用**bpin**增加相应缓存块的引用计数refcnt，这样它们就不会被逐出（见下文课上内容），因此不会被提前写入磁盘（否则会破坏原子性）。**注意，以上所有这些操作都是在内存中发生，这里并没有实际的磁盘操作。**此时，在事务被提交以前，位于内存中的缓存块副本是唯一的修改记录，其它FS调用读取这些块时，能够看到它们的更新。log_write还注意到了，一个块被提交多次的情况，这时不是额外分配日志空间给它，而是继续使用日志区域中相同的槽位。这样，在没有优化之前，对相同的几个块进行十几次更新，需要十几块日志块，但现在只需要几个块的槽位，从而节省了日志空间。最终，每个缓存块只有一份更新后的副本会被写入到磁盘上，这种优化称为吸收Absorption。

最后，调用**end_op**标志着这次FS系统调用的结束，因此要准备提交事务。首先，它减少计数outstanding，表示当前FS系统调用处理将结束；然后检查自己是否是当前的最后一个FS系统调用，如果是，那么就调用commit提交当前日志区域中的所有事务。

整个commit的过程分为四个阶段。第一步是write_log，将位于内存中的，更新后的缓存块写入磁盘上的日志里；第二步是write_head，将logheader写入磁盘，如果这一步成功完成，代表事务被正式提交；第三步是install_trans，即加检查点的过程（上面有提到加检查点即将日志中的事务（元数据和数据更新）写入磁盘的最终位置上。）；最后一步是清除日志，将logheader的计数n重置为0，并且写入磁盘上完成更新。如课上所示。

![img](assets\clip_image002-1729429585928-1.jpg)

write_log的工作就是将所有位于内存中的，更新后的缓存块，按顺序写入到磁盘的日志区域上。就相当于bcache写进disk上的这一部分（下图）这里对应数据日志四部曲中的**日志写入**。

![img](assets\clip_image004-1729429585928-2.jpg)

write_head做的事情很简单，就是将更新后的logheader写回磁盘上。这里对应数据日志四部曲中的**日志提交**，一旦这一步完成，就代表事务提交真正完成，因此从这里开始，到日志被清除以前，期间发生的crash都可以恢复。（在header中有效block为n，其中block[0]=45，说明等以下要往块号45中写入内容，内容为下图存储的数据）

![img](assets\clip_image006-1729429585928-3.jpg)

install_trans根据logheader的指示（logheader中的数组指示了每个日志块最终应该被写到磁盘的哪个位置），将每个logged blocks写到目的磁盘位置上，然后**bunpin**其在内存中的相应缓存块，这样Buffer Cache可以回收它。这里对应数据日志四部曲中的**加检查点**，一旦这一步完成，那么本次事务就成功更新到磁盘上，因此可以准备释放日志块。（在这一步中crash了就会重新install log）

commit的最后一步，将logheader的计数n置0，并且将logheader写回到磁盘上。这里对应数据日志四部曲中的**释放**，因为n已经被标记为0，所以日志区域中的块现在可以被重用。注意，我们应该等待这一步完成之后，才能回到end_op中，将commiting置0，表示日志系统提交完成并处于空闲。这个顺序很重要，先释放旧日志块再开始处理新事务，否则后续发生crash时，可能会使用前一个事务的日志块来恢复。

 

crash发生时，文件系统如何恢复？答案是，在系统的启动阶段，第一个用户进程init会调用fsinit初始化文件系统。而在fsinit函数中，调用了initlog来初始化日志系统。

initlog它做的事情就是从超级块上，读取关于日志系统的信息，包括日志区域的起始位置，日志区域的大小等。然后，它就调用recover_from_log开始恢复（不管有没有需要恢复的日志都可以调用它，这并不带来负面影响）。

recover_from_log如下所示，做的事情很简单，读出磁盘上的logheader，如果计数n=0，代表日志系统不需要进行恢复，因此跳过recovery继续启动；如果计数n不等于0，代表有需要重放的日志，因此我们回到数据日志四部曲中的加检查点，再次调用install_trans重新执行加检查点过程。最后在函数退出点，清除旧日志。

 

begin_op和end_op的成对使用，相对于告诉文件系统，现在将要进行一系列块的更新，而且我们希望这些块的更新是原子的，所以在我发出end_op之前，不要擅自将任何一块或几块的更新写入到磁盘上。





## 课上内容

logging。这是来自于数据库的一种解决方案。它有一些好的属性：

 

首先，它可以确保文件系统的系统调用是原子性的。比如你调用create/write系统调用，这些系统调用的效果是要么完全出现，要么完全不出现，这样就避免了一个系统调用只有部分写磁盘操作出现在磁盘上。

 

其次，它支持快速恢复（Fast Recovery）。在重启之后，我们不需要做大量的工作来修复文件系统，只需要非常小的工作量。这里的快速是相比另一个解决方案来说，在另一个解决方案中，你可能需要读取文件系统的所有block，读取inode，bitmap block，并检查文件系统是否还在一个正确的状态，再来修复。而logging可以有快速恢复的属性。

 

最后，原则上来说，它可以非常的高效，尽管我们在XV6中看到的实现不是很高效。

 

logging的基本思想还是很直观的。首先，你将磁盘分割成两个部分，其中一个部分是log，另一个部分是文件系统，文件系统可能会比log大得多。（log write）当需要更新文件系统时，我们并不是更新文件系统本身。假设我们在内存中缓存了bitmap block，也就是block 45。当需要更新bitmap时，我们并不是直接写block 45，而是将数据写入到log中，并记录这个更新应该写入到block 45。对于所有的写 block都会有相同的操作，例如更新inode，也会记录一条写block 33的log。

所以基本上，任何一次写操作都是先写入到log，我们并不是直接写入到block所在的位置，而总是先将写操作写入到log中。

（commit op）之后在某个时间，当文件系统的操作结束了，比如说我们前一节看到的4-5个写block操作都结束，并且都存在于log中，我们会commit文件系统的操作。这意味着我们需要在log的某个位置记录属于同一个文件系统的操作的个数，例如5。（在这里crash的话就会恢复）

（install log）当我们在log中存储了所有写block的内容时，如果我们要真正执行这些操作，只需要将block从log分区移到文件系统分区。我们知道第一个操作该写入到block 45，我们会直接将数据从log写到block45，第二个操作该写入到block 33，我们会将它写入到block 33，依次类推。（在这里crash的话就会重新install，执行多次和执行一次的效果是一样的）

（clean log）一旦完成了，就可以清除log。清除log实际上就是将属于同一个文件系统的操作的个数设置为0。

 

在XV6中，我们会看到数据有两种状态，是在磁盘上还是在内存中。内存中的数据会在crash或者电力故障之后丢失。

在磁盘上在最开始有一个header block，也就是我们的commit record，里面包含了：数字n代表有效的log block的数量、每个log block的实际对应的block编号，之后就是log的数据，也就是每个block的数据，依次为bn0对应的block的数据，bn1对应的block的数据以此类推。

 

当文件系统在运行时，在内存中也有header block的一份拷贝，**拷贝中也包含了****n****和block****编号的数组。这里的block****编号数组就是log****数据对应的实际block****编号，并且相应的block****也会缓存在block cache****中**，这个在Lec14有介绍过。与前一节课对应，log中第一个block编号是45，那么在block cache的某个位置，也会有block 45的cache。

![img](assets\clip_image002-1729429612659-7.jpg)begin_op表明想要开始一个事务，在最后有end_op表示事务的结束。**并且事务中的所有写****block****操作具备原子性**，这意味着这些写block操作要么全写入，要么全不写入。XV6中的文件系统调用都有这样的结构，最开始是begin_op，之后是实现系统调用的代码，最后是end_op。在end_op中会实现commit操作。

 

在begin_op和end_op之间，磁盘上或者内存中的数据结构会更新。但是在end_op之前，并不会有实际的改变（注，也就是不会写入到实际的block中）。任何一个文件系统调用的begin_op和end_op之间的写操作总是会走到log_write。

 

中间的一些内容看课前预习。现在看代码部分。

![img](assets\clip_image002-1729429634435-9.jpg)

看一下这里的写磁盘操作：

 

首先是前3行的bwrite 3，4，5。因为block 3是第一个log data block，所以前3行是在log中记录了3个写操作。这3个写操作都保存在log中，并且会写入到磁盘中的log部分。

 

第4行的bwrite 2。因为block 2是log的起始位置，也就是log header，所以这条是commit记录。

 

第5，6，7行的bwrite 33，46，32。这里实际就是将前3行的log data写入到实际的文件系统的block位置，这里实际是install log。（这里造成了性能降低，因为我们写入了两次磁盘操作）

 

第8行的bwrite 2，是清除log（注，也就是将log header中的n设置为0）。到此为止，完成了实际上的写block 33，46，32这一系列的操作。第一部分是log write，第二部分是install log，每一部分后面还跟着一个更新commit记录（注，也就是commit log和clean log）。

 

前面说到XV6的文件系统有一定的复杂性，接下来我将介绍一下三个复杂的地方或者也可以认为是三个挑战。

 

第一个是cache eviction。假设transaction还在进行中，我们刚刚更新了block 45，正要更新下一个block，而整个buffer cache都满了并且决定撤回block 45。在buffer cache中撤回block 45意味着我们需要将其写入到磁盘的block 45位置，这里会不会有问题？如果我们这么做了的话，会破坏什么规则吗？是的，如果将block 45写入到磁盘之后发生了crash，就会破坏transaction的原子性。这里也破坏了前面说过的write ahead rule，write ahead rule的含义是，你需要先将所有的block写入到log中，之后才能实际的更新文件系统block。所以buffer cache不能撤回任何还位于log的block。在介绍log_write函数时，其中调用了一个叫做bpin的函数，这个函数的作用就如它的名字一样，将block固定在buffer cache中。它是通过给block cache增加引用计数来避免cache撤回对应的block。同样通过bunpin可以减少refcnt。

 

第二个挑战见第一页:文件系统操作必须适配log的大小。这里还需要注意，因为block在落盘之前需要在cache中pin住，所以buffer cache的尺寸也要大于log的尺寸。

 

最后一个要讨论的挑战是并发文件系统调用。让我先来解释一下这里会有什么问题，再看对应的解决方案。假设我们有一段log，和两个并发的执行的transaction，其中transaction t0在log的前半段记录，transaction t1在log的后半段记录。可能我们用完了log空间，但是任何一个transaction都还没完成。现在我们能提交任何一个transaction吗？我们不能，因为这样的话我们就提交了一个部分完成的transaction，这违背了write ahead rule，log本身也没有起到应该的作用。所以必须要保证多个并发transaction加在一起也适配log的大小。所以当我们还没有完成一个文件系统操作时，我们必须在确保可能写入的总的log数小于log区域的大小的前提下，才允许另一个文件系统操作开始。

XV6通过限制并发文件系统操作的个数来实现这一点。在begin_op中，我们会检查当前有多少个文件系统操作正在进行。如果有太多正在进行的文件系统操作，我们会通过sleep停止当前文件系统操作的运行，并等待所有其他所有的文件系统操作都执行完并commit之后再唤醒。这里的其他所有文件系统操作都会一起commit。有的时候这被称为group commit，因为这里将多个操作像一个大的transaction一样提交了，这里的多个操作要么全部发生了，要么全部没有发生。

 

回到beginop：首先，如果log正在commit过程中，那么就等到log提交完成，因为我们不能在install log的过程中写log；其次，如果当前操作是允许并发的操作个数的后一个，那么当前操作可能会超过log区域的大小，我们也需要sleep并等待所有之前的操作结束；最后，如果当前操作可以继续执行，需要将log的outstanding字段加1，最后再退出函数并执行文件系统操作。

 

再回到endop：在最开始首先会对log的outstanding字段减1，因为一个transaction正在结束；其次检查committing状态，当前不可能在committing状态，所以如果是的话会触发panic；如果当前操作是整个并发操作的最后一个的话（log.outstanding == 0），接下来立刻就会执行commit；如果当前操作不是整个并发操作的最后一个的话，我们需要唤醒在begin_op中sleep的操作，让它们检查是不是能运行。

outstanding它表示的是当前正在并发执行的文件系统操作的个数，MAXOPBLOCKS定义了一个操作最大可能涉及的block数量。在begin_op中，只要log空间还足够，就可以一直增加并发执行的文件系统操作。所以XV6是通过设定了MAXOPBLOCKS，再间接的限定支持的并发文件系统操作的个数）

 

## lab内容

![img](assets\clip_image002-1729429677980-11.jpg) 

这个函数的功能是将逻辑块号bn转换为物理块号（返回地址）7-11行是处理直接块。12-26是处理间接块。(看清楚一个变量是addr，传进来的结构体是addrs）先解释直接块的部分：

![img](assets\clip_image004-1729429677980-12.jpg)

 

addr = ip->addrs[2] = 0 // addr 为 0，未分配，所以给它分配新块，假设为其分配了一个新的物理块地址103，那么就返回103.

 

再解释间接块的部分：

![img](assets\clip_image006-1729429677980-13.jpg)先调整块编号，则bn=2，因为bn小于256，说明是间接块，

看上面那个数组，最后一个为0（即间接块的物理地址还没有分配），所以先分配新的物理地址给间接块。

效果就会如下说是（假设分配了200这个物理地址给间接块）

ip->addrs = [100, 101, 102, ..., 111, 200] // 直接块 [100, 101, ..., 111]，间接块地址 200

之后读取间接块（即200）对应的块数据，将数据转换为指向块地址数组的指针a（a[bn]就是实际的数据块了！）

 

a = [300, 0，0，0,…,0] // 数组 a 存储的块地址可能如此所示

 

a[2]为0，表示未分配，所以要后来配一个新的物理块地址给a[2]，假设是301，那么就返回301。

 

假如已经分配的情况下：

ip->addrs = [100, 101, 102, ..., 111, 200] // 直接块 [100, 101, ..., 111]，间接块地址 200

那就会跳过16 17行。假设间接块（200）已经存储了一些数据块的地址：

a = [300, 301, 302, ..., 427] // 数组 a 存储的块地址

a【2】不为0，说明已经分配，直接返回物理块地址302

 

要添加2级间接块，就模仿这段代码就可以了。由于有两级表，求在第一级表中是哪个位置，可以用除法，bn/256（即NINDIRECT），求在第二级表中哪个位置可以用取余bn%256 。itrunc也是模仿着写就好，记得双层循环，判断条件应该都是小于256（因为一级表里面总共256个，二级表也是，所以判断条件应该是小于256而不是小于256*256）

 

 

符号链接与硬链接的区别

符号链接：

1是一个独立的文件（所以要创建个新inode,里面的数据类型应该是symlink而不是file，dir之类的），包含指向目标文件或目录的路径。

2如果目标文件被删除，符号链接会变成“悬空链接”（dangling link），指向一个不存在的路径。

3可以跨文件系统创建符号链接。

硬链接：

1是目标文件的另一个目录项，指向相同的 inode。

2如果目标文件被删除，硬链接仍然有效，因为它们共享相同的 inode 和数据块。

3不能跨文件系统创建硬链接。

 

符号链接的创建过程

分配 inode：为符号链接分配一个新的 inode，设置其类型为 T_SYMLINK。

存储路径：将目标路径存储在符号链接 inode 的数据区中。

创建目录项：在指定的路径创建一个新的目录项，将其指向符号链接的 inode。

 

symlink(char *target, char *path)

符号链接是个什么东西，参考 [csdn lab fs 一文](https://blog.csdn.net/weixin_44465434/article/details/111584291)：

·     它也是一个文件，它保存在 target 路径这个字符串

·     它有两种打开方式：

o  follow 方式：打开 target 指向的文件

o  nofollow 方式：打开文件本身

像 symlink("/usr/a", "/usr/b") 这样调用，其实就是在 /usr/ 下创建一个文件 b，它指向同路径下的另一个文件 a。如果是 follow 方式打开 b，其实是打开了 a；否则会直接打开 b，但打开的样子是什么样的，我也不知道，实际也不用关心

所以 symlink() 其实就只有一个逻辑就是创建文件（一切皆文件），直接调用 create() 就行了。需要注意的是创建出来的文件会占用一个 inode，但实际上一个文件只有在真正使用的时候（比如读写文件）才需要 inode。你现在只创建出来，还未到真正时候，所以应该调用 iunlockput() 释放掉占用的 inode（**否则，会出现****inodes****不足的错误**），需要用的时候再通过 namei() 某个文件名就可以取回 inode

可以通过`namei`函数获取相应路径对应的`inod`