## 课前后内容

同步操作的实现，需要给对象关联一个互斥体，这个互斥体就可以叫做锁

锁的作用是，保证同一竞争资源在同一时刻只会有一个线程占有

①自旋锁与互斥锁都是为了实现保护资源共享的机制。

②无论是自旋锁还是互斥锁，在任意时刻，都最多只能有一个保持者。

③获取互斥锁的线程，如果锁已经被占用，则该线程将进入睡眠状态；获取自旋锁的线程则不会睡眠，而是一直循环等待锁释放。

总结

自旋锁：线程获取锁的时候，如果锁被其他线程持有，则当前线程将循环等待，直到获取到锁。

自旋锁等待期间，线程的状态不会改变，线程一直是用户态并且是活动的(active)。

自旋锁如果持有锁的时间太长，则会导致其它等待获取锁的线程耗尽CPU。![img](assets\clip_image002-1729266037684-1.jpg)

 

32位计算机：1字=32位=4字节，64位计算机：1字=64位=8字节；01中的其中一个就是一位(bit)，8个位组成一个字节(Byte，简写为B)，8bit(位)=1Byte(字节)，1024Byte(字节)=1KB，1Byte=1B

 

 

页表相关知识汇总：

页表中能够包含很多页表项，大小固定为4字节，页表中记录的是物理地址。

1.（逻辑）地址空间：简单的理解为程序进程在运行时系统为其分配的运行内存空间。

2.页面（页）：将用户进程的（逻辑）地址空间划分为固定且大小相等的一个个区域。一页的大小4KB

注：页面和页是同一概念！！！划分出来的一个区域为一个页（页面）！！！

0页对应页号0，1页对应页号1

3.页面大小：页面的一个划分区域的大小。

4.页号：表明页面在划分区域过后的次序。页号有多少，页就有多少个

5.位移量、偏移量、页内地址：页内地址即位移量或称偏移量，三者大小都等同于页面大小！！！不要着急问为什么，下面进行分析：

书上有类似下面这个图![img](assets\clip_image002-1729266054716-3.jpg)

 

 

注意这是分页地址中的地址结构！！！并不是页面！！！而是系统存储方式的一种结构！！！其中的页号在上面已经提及，而其中的页内地址即页面大小（用于之后将其中的内容放在内存物理地址中），可以通过下面这图来更好理解：

最左边的一整个为一个进程（逻辑）地址空间，每一项才是一个页面！！！

 ![img](assets\clip_image004.jpg)

6.页表：系统为每个进程建立的页面映像表，即下图或上图的中间一整块部分。

7.页表项pte：页表的其中一项，即下图的中间一整块部分的其中一行（如：页号为2且物理块号为6的整体为一个页表项。页表的其中一项，即页表中的一行。每一项都记录了逻辑页号和物理页框号之间的映射关系，以及一些控制位信息，如有效位、保护位等。

8.页表项大小：中间一整块部分的其中一行所占大小。

9.页表长度：指页表项的个数，即下图中间部分一共有几行，有几行页表长度就为多少。

根据这张图可以分析以上所提的概念：

在这个图当中最左边的整个叫用户程序（逻辑地址空间），通过划分区域形成若干项，其中的每一项叫做页面，大小叫做页面大小，页面通过页表（页面映像表）对应物理块号，物理块号再对应与内存中的每一个实际（物理）地址，此时才将页面的内容（即页内地址）放在该实际（物理）地址中。

10.物理块、页框：物理块即页框！！！是将内存空间划分为与先前页面的大小相等的若干块（此时才能将页面大小（页内地址）完全放入划分的内存中，在上图表示的区域为最右边内存实际(物理）地址的每一行，一个物理块或页框就是其中的一行。

![img](assets\clip_image002-1729266075088-6.jpg)![img](assets\clip_image004-1729266075088-7.jpg)

 

 

1）外层页号对外层页的计数，存放外层页号，位数 = log2（外层页个数）

 

2） 外层页存放的页表项是内层页的索引，外层页大小 = 内层页大小，外层页内地址位数 = log2（页面大小 / 页表项的大小）

 

3）页内地址位数 = log2（页面大小），存放物理地址

 

已知系统为48位地址，页面大小4KB，页表项大小为8B，使用页式存储，则要采用多少级页表，页内偏移多少位 ?

页面大小 = 2 ^12 B，故页内偏移12位

页号位数 = 48-12 = 36

4KB / 8B = 2 ^9 ，一个页面能装下2 ^9个页表项

按理来说，外层页以及内层页的大小都应为一个页面大小，外层页号需不超过一个页面大小，不然需要对外层页号再次分页

因此，36/9 = 4 ，需要四级页表

 

有了页表，每个进程在访问物理内存时，只需要给出属于自己空间内的虚拟地址，剩余的地址转换工作就交给内存管理单元MMU（Memory Management Unit）来完成，如下图所示，避免了所有进程在同一物理内存上访存的操作，通过一些页表映射的规则，我们也能禁止进程之间随意访问对方的内存，因此使用页表增强了进程之间的隔离性；原来单一的物理内存，在我们引入分页和页表，构建起了虚拟内存系统之后，单一的物理地址空间，现在被我们映射到多个独立的虚拟地址空间中，这实现了物理内存的复用。

![img](assets\clip_image006.jpg)

 

RISC-V页表的简化图如下所示，如果我们将页表看成一个简单的线性数组，那么一个页表可以保存2^27个PTE，这是因为在虚拟地址有效的39位中，高27位是用来索引PTE的。

![img](assets\clip_image008.jpg)每个PTE由44位的物理页帧号PPN和10位的标志位Flags组成。有效位为54位的PTE可以用8B的大小来存储，这刚好是一个uint64类型。虚拟地址有效的39位中，还有低12位称为（页内）偏移量Offset。在页表转换一个虚拟地址时，首先提取出有效的39位，用高27位来索引对应的PTE，从PTE中我们可以得到44位的PPN，并且根据Flags检查一些权限，最后将44位的PPN和原虚拟地址的低12位Offset加在一起，得到最后56位的有效物理地址，接着就可以访问物理内存。

 

在多级页表中：每级页表的大小都被设计为4KB，刚好能装进一页物理帧内。前面提过，PTE用uint64类型来保存，因此一个PTE占用8B=64bit的空间，所以一个页表可以包含512个PTE。在每一级页表中，都取27位索引的其中9位来找到对应的PTE。通过查找前两级页表的PTE，可以访问新的物理页帧，在该物理页帧内保存着下一级的页表。当查找最后一级页表的PTE时，才将PPN和Offset结合，得到虚拟地址所映射的真正物理地址，然后再访问用户或内核需要的内容。

页表是由硬件而不是os实现的。

 

建议把虚拟内存理解为一种机制而不是具体的物件可能会来得更好，比如你可以认为它指代的是，由内核提供的，管理虚拟地址空间和物理内存的一些抽象方法和机制。

 

QEMU仿真的RAM，将从物理地址0x80000000（KERNBASE）开始，至少到0x86400000为止（PHYSTOP，在kernel/memlayout.h中定义其值为0x88000000，所以xv6的RAM实际大小为128M）。只有从KERNBASE到PHYSTOP才对应真正的DRAM芯片。位于PHYSTOP上方，未使用的空间是没有DRAM芯片与之对应的，通过放置新的DRAM芯片，这部分空间可以被扩展并使用。而位于KERNBASE下方，访问相应的物理地址，实际上是直接访问相关I/O设备的控制寄存器，而不是访问DRAM芯片。但要记住，phystop以下地址几乎是一一对应的，只有在它之上才是映射到dram中。



### 以下两张图片记住

![img](assets\clip_image002-1729266117237-12.jpg)

 

在xv6内核的启动阶段时，页表是被禁用的。为了告诉RISC-V的分页硬件，现在可以使用页表了，内核必须将根页表的物理地址写入到satp寄存器中。每个CPU都有自己的satp寄存器。CPU在执行指令时，将使用自己的satp寄存器里指向的根页表，完成指令中虚拟地址的转换。正因为每个CPU有自己的satp寄存器，因此不同CPU可以使用不同的页表。在内核未启用页表的时候，访问RAM以及经过内存映射的设备控制寄存器时，内核的虚拟地址将采用直接映射的方式进行转换，即虚拟地址与实际物理地址相同。内核对物理内存的读或写变简单了。例如在进行系统调用fork时，fork会为子进程分配内存，内存分配器因此返回指向一块物理内存的物理地址，因为是直接映射，所以fork直接把返回的物理地址当成虚拟地址用（指令对虚拟地址进行操作），然后通过一系列指令将父进程的用户内存复制到子进程。

 

看一下知乎文档3.3节。核心为walk和mappages，walk为给定的虚拟地址，找到其相应的PTE，如果PTE不存在则新分配一页使之有效，它模仿的是真实分页硬件查找页表的过程，可以看成是查找页表的软件实现，在内核或进程的页表未初始化时，内核就用它来转换相关虚拟地址；mappages为给定输入的映射建立PTE，更新页表。

 

每次分配和回收都以页为单位，一页大小4KB，通过一个空闲物理帧链表free-list，将空闲的物理帧串起来保存。页表、用户内存、内核栈、管道缓冲区等操作系统组件需要内存时，内核就从free-list上摘下一页或者多页分配给它们；在回收已经分配出去的内存时，这些被回收的物理帧，内核将它们一页页地重新挂到free-list上。

 

用户进程虚拟地址空间的布局如下图所示。与第二章里的图相比，在这里我们看到了更多细节，尤其是用户栈的细节。图中用户栈的初始内容是由系统调用exec产生的。在初始的用户栈上包括了：各命令行参数的字符串，指向各命令行参数的指针数组argv[ ]，用于从调用main(argc, argv[ ])返回的其它参数（argc、argv指针和伪造的返回pc值）。在初始用户栈的内容被设置好之后，用户程序就返回并开始执行main 函数。



值得注意的地方有两点：首先是这里的保护页，和内核虚拟地址空间中那些内核栈之间的保护页有所不同。这里的保护页是有实际的物理帧对应的，即内核确实为用户进程分配这一页（标志位为RWV，没有U）；而在内核空间下，内核栈之间的保护页PTE_V无效，并没有实际分配物理页。然后是user text和data，xv6为了简单起见，将它们放在了同一页内。实际上现在的操作系统都会将它们放在不同的页内，这一点也可以通过在编译时指定-N选项来强制实现。

 ![image-20241018234254275](assets\image-20241018234254275.png)

Sbrk是一个系统调用，用户进程调用它以增加或减少自己拥有的物理内存（proc->sz）。growproc根据增加或减少内存的需要，又分别调用uvmmalloc和uvmdealloc来满足请求。uvmalloc通过调用kalloc来分配物理内存，并调用mappages来更新页表，并设置PTE的5个标志位都置位。uvmdealloc调用uvmunmap来回收已分配的物理内存。

 

Exec():

1.exec通过路径名打开文件，然后读取该文件的ELF Header（kernel/elf.h）。xv6的所有应用程序以通用的ELF格式来描述，一个ELF二进制文件大概这样组成（更准确的定义，建议查阅相关资料，这里进行简单的不严谨的说明）：一个ELF Header，后面紧跟一系列的Program Section Headers。每个Program Section Header都对应一段需要加载到内存中的程序，xv6的应用程序只有一个Program Section Header，而在其它操作系统上可能有好几个。
 2.exec读取了文件系统上的文件之后，第一件事就是先检查该文件是否包含ELF二进制文件。接着，exec为用户进程调用proc_pagetable，通过uvmcreate创建一个空的用户页表，接着只在该页表上添加了trampoline和trapframe的映射，其它的虚拟地址空间都暂时为空。

3.然后，exec对于每个程序段，先是调用uvmalloc分配足够的物理帧，更新了用户页表。然后调用loadseg加载程序段到这些物理帧中。loadseg将虚拟地址传给walkaddr，walkaddr又通过walk查找相关PTE，将va转换为pa，最后walkaddr成功返回uvmalloc分配的物理帧的物理地址，loadseg再调用readi，真正地将程序段加载到物理内存中。

4.exec首先分配两页物理帧。第一页用作保护页，通过调用uvmclear将PTE_U设为无效，这样在用户空间下不能访问它；第二页留给用户栈，从栈顶开始，将命令行参数的字符串、指向这些命令行参数的指针数组argv[ ]、用于从调用main(argc, argv[ ])返回的其它参数（argc、argv指针和伪造的返回pc值）推入用户栈内。

5.最后，当用户程序的程序段都成功加载，用户栈也设置完毕后，内核确定这次exec将要成功时，exec就清除进程的旧内存映像，即释放旧页表所占用的物理内存，并准备使用新的页表。然后系统调用exec将会顺利完成并返回，该进程将执行一个新的用户程序。

 

每个进程都有完全属于自己的地址转换表，所以即使shell在0x1000存了一些数据，ls也在0x1000存了一些数据，但经过翻译后对应的物理内存还是不一样的。

MMU是CPU的一部分，每个处理器core都有一个MMU，包含：TLB：是页表的高速缓存，存储着最近转化的一些目录项（要不然每次都查找三次，三级页表就费时间，所以做个cache）；Table Walk Unit：负责从页表中读取虚拟地址对应的物理地址。sfence_vma函数用于刷新TLB。

 

"高地址"指的是数值较大的内存地址，即远离0的地址。相对地，"低地址"则指数值较小的内存地址，即靠近0的地址。



## 课上内容

通常来说，内存地址对应关系的表单也保存在内存中。所以CPU中需要有一些寄存器（在riscv中是stap寄存器）用来存放表单在物理内存中的地址。现在，在内存的某个位置保存了地址关系表单，我们假设这个位置的物理内存地址是0x10。那么在RISC-V上一个叫做SATP的寄存器会保存地址0x10。这样，CPU就可以告诉MMU，可以从哪找到将虚拟内存地址翻译成物理内存地址的表单。(故可见mmu不保存page table，而是stap从物理内存读取pt然后va通过mmu完成翻译）SATP寄存器包含了需要使用的地址转换表的内存地址。所以ls有自己的地址转换表，cat也有自己的地址转换表。每个进程都有完全属于自己的地址转换表。

 

寄存器是64bit的，所以有多少个地址呢？是的，2^64个地址（01所以是2）。

 

RISC-V中，一个page是4KB，也就是4096Bytes。这个大小非常常见，几乎所有的处理器都使用4KB大小的page或者支持4KB大小的page。首先对于虚拟内存地址，我们将它划分为两个部分，index和offset，index用来查找page，offset对应的是一个page中的哪个字节。当MMU在做地址翻译的时候，通过读取虚拟内存地址中的index（27bit）可以知道物理内存中的page号，这个page号对应了物理内存中的4096个字节。之后虚拟内存地址中的offset指向了page中的4096个字节中的某一个，假设offset是12（12bit对应一个page的4096B，一页是连续的4096B，所以物理内存是以4096为粒度使用的，而不是以单个内存地址为力度），那么page中的第12个字节被使用了。将offset加上page的起始地址，就可以得到物理内存地址。

物理内存地址是56bit，其中44bit是物理page号（PPN，Physical Page Number），剩下12bit是offset完全继承自虚拟内存地址（也就是地址转换时，只需要将虚拟内存中的27bit翻译成物理内存中的44bit的page号，剩下的12bitoffset直接拷贝过来即可）。

 

27bit的index，实际上是由3个9bit的数字组成（L2，L1，L0）。前9个bit（L2）被用来索引最高级的page directory，一个directory是4096Bytes，就跟page的大小是一样的。Directory中的一个条目被称为PTE（Page Table Entry）是64bits，就像寄存器的大小一样，也就是8Bytes。所以一个Directory page有512个条目。

 

实际上，SATP寄存器会指向最高一级的page directory的物理内存地址，之后我们用虚拟内存中index的高9bit用来索引最高一级的page directory(注，2^9 = 512，正好可以索引到一条 PTE)，这样我们就能得到一个PPN，也就是物理page号。这个PPN指向了中间级的page directory。当我们在使用中间级的page directory时，我们通过虚拟内存地址中的L1部分完成索引。接下来会走到最低级的page directory，我们通过虚拟内存地址中的L0部分完成索引。在最低级的page directory中，我们可以得到对应于虚拟内存地址的物理内存地址。（va=0x22（应该是9个bit，举例这里是2X4=8bit，因为16进制位置可以表示4个二进制位）

第一次理解：通过stap查阅到底是哪个物理内存地址存放了地址对应表单page directory，比如0x11存放了表单，那va就从0x11地址查表单，发现va=0x22对应pa=3x11,即PPN3x11指向了中间级的表单page directory，然后通过L1索引va=0x33，查询3x11中存放的表单，发现va=0x33对应pa=4x22，那么PPN4x22指向了最低级的表单page directory，最后用L0索引va=0x44，查询4x22中的表单得到对应于虚拟内存地址的物理内存地址，这里说的不够准确，准确应该看如下链接：https://blog.csdn.net/zhizhengguan/article/details/121276581   ，https://www.zhihu.com/tardis/zm/art/64978946?source_id=1005   。）

在多级页表系统中，其实每级页表都可以视为一种“虚拟地址”向“物理地址”的转换，只是这里的“虚拟地址”是待转换的虚拟地址的一个位域子集，而除了最后一级页表PTE是直接指向物理页面的，其他级别页表里的“物理地址”都是指向对应下一级页表的首地址。

为什么可以省空间，可见：https://blog.csdn.net/fuyuande/article/details/117616433 ， ‘

 第二次理解:一个虚拟地址va有8B=64bit,其中 25bit是不用的，然后到L2 L1 LO OFFSET;L2利用stap 寄存器(存了一级页表的地址)得到一个“对应表”，用它来査询L2va对应的物理地址 pa2，之后L1用这个物理地址 pa2得到一张新的对应表，用这个对应表来査询 L1va对应的物理地址 pa1;最后,L0用这个物理地址 pa1得到一张新的对应表，用这个对应表来查询L0va对应的物理地址pa0。但注意，上述所说的pa应该都是指的PPN（44bit），翻译完pa0后再加上12bit的0，这样就得到了完整的最终的56bit物理地址。这里要求每个page directory都与物理page对齐（也就是page directory的起始地址就是某个page的起始地址，所以低12bit都为0）。pa2和pa1，pa0都可见是44+10（flag）=54bit，见下图，说明有10bit未使用。个人认为最终的是我们所需要的，中间得到的这些54bit物理地址就是用于L210来查对应的下一级page directory的。

![img](assets\clip_image002-1729266205884-16.jpg)（注：通常page directory是用来索引page table或者其他page directory物理地址的表单，但是在课程中，page table，page directory， page directory table区分并不明显，可以都认为是有相同结构的地![img](assets\clip_image004-1729266205884-17.jpg)址对应表单）。

可以向同一个物理地址映射两个虚拟地址，你可以不将一个虚拟地址映射到物理地址。可以是一对一的映射，一对多映射，多对一映射。如果多个进程都将内存映射到了同一个物理位置，会优化合并到同一个地址。

kvminit函数的第一步是为最高一级page directory分配物理page（注，调用kalloc就是分配物理page）。之后，通过kvmmap函数，将每一个I/O设备映射到内核。

第三次理解见print pgtbl lab

![img](assets\clip_image006-1729266205884-18.jpg)
 将地址0x10000000向右移位12bit，这样可以得到虚拟地址的高27bit=0x10000，4乘以7等于28（index部分）。之后我们再对这部分右移位9bit，并打印成10进制数，可以得到128，这就是中间级page directory中PTE的序号。

walk函数模拟了MMU，返回的是va对应的最低级page table的PTE



## labs内容

### Print a page table

%p是打印地址（指针地址）的，是十六进制的形式，但是会全部打完，即有多少位打印多少位。

页表的数据结构是pagetable_t，在上面定义宏的代码中可以看到pagetable_t实际上就是uint64 *，即一个指针，所以页表实际上是一个数组。

关键是要理解level，递归调用的时候要level++

这些宏定义是在处理与RISC-V架构中的Sv39分页机制相关的地址转换。Sv39是RISC-V的一种分页模式，支持39位虚拟地址空间。这里的宏定义用于地址转换和提取特定的页表项（PTE）信息。下面是对每个宏定义的解释：

PA2PTE(pa): 将物理地址转换为页表项。它首先通过右移12位去掉物理地址的低12位（这些位在页表项中不存储），然后左移10位，为页表项中的标志位留出空间。

PTE2PA(pte): 将页表项转换回物理地址。它通过右移10位去掉页表项中的标志位，然后左移12位，恢复为完整的物理地址。

PTE_FLAGS(pte): 从页表项中提取标志位。它通过与0x3FF进行位与操作，0x3FF是一个9位全为1的掩码，这样可以获取页表项的低10位标志位。

PXMASK: 定义了一个掩码，用于提取9位的页表索引。

PXSHIFT(level): 根据页表的层级计算在虚拟地址中对应索引的位移。PGSHIFT是基础位移量，每一级页表索引占用9位。

PX(level, va): 提取虚拟地址中给定层级的页表索引。它首先根据层级计算位移，然后右移相应的位数，并与PXMASK进行位与操作，以确保只获取9位的索引值。

MAXVA: 定义了虚拟地址空间的最大值。Sv39模式下，虚拟地址是39位的，但这里的定义是为了避免符号扩展问题，所以实际上使用的是38位，即1L << (9 + 9 + 9 + 12 - 1)。这里的计算考虑了三级页表各9位索引和12位页偏移，总共38位。

这些宏定义是处理虚拟地址和物理地址转换、页表项操作的基础，对于理解和实现RISC-V的Sv39分页机制至关重要。

有当页表项既有效又没有设置任何读、写、执行权限时，整个表达式才为真。这通常用于检测指向下一级页表的页表项，而不是直接映射到物理内存的页表项。x表示执行权限。

+========+=========+=========+=========+=========+===========+

| 签名域       | 顶级目录    | 顶级页表    | 中级页表    | 低级页表    | 页内偏移  |

+========+=========+=========+=========+=========+===========+

  16位           	 9位        	9位          	9位       	  9位       	  12位

1使用虚拟地址的最高9位(63..56)作为索引,在顶级页目录表中查找顶级页表的基地址。

1使用虚拟地址的最高9位(63..56)作为索引,在顶级页目录表中查找顶级页表的基地址。

2使用接下来9位(55..47)作为索引,在顶级页表中查找中级页表的基地址。

3使用再接下来9位(46..38)作为索引,在中级页表中查找低级页表的基地址。

4使用后9位(37..30)作为索引,在低级页表中查找最终的页表项,获取物理页帧号。

5将物理页帧号与最低12位(29..0)的页内偏移拼接,得到最终物理地址。

 

 

page table 0x0000000087f6b000（init）

​    ..0: pte 0x0000000021fd9c01 pa 0x0000000087f67000

​    .. ..0: pte 0x0000000021fd9801 pa 0x0000000087f66000

​    .. .. ..0: pte 0x0000000021fda01b pa 0x0000000087f68000 (text)

​    .. .. ..1: pte 0x0000000021fd9417 pa 0x0000000087f65000 (data)

​    .. .. ..2: pte 0x0000000021fd9007 pa 0x0000000087f64000 (guard page，在stack下方）

​    .. .. ..3: pte 0x0000000021fd8c17 pa 0x0000000087f63000 (stack)

​    ..255: pte 0x0000000021fda801 pa 0x0000000087f6a000

​    .. ..511: pte 0x0000000021fda401 pa 0x0000000087f69000

​    .. .. ..509: pte 0x0000000021fdcc13 pa 0x0000000087f73000 (usyscall)

​    .. .. ..510: pte 0x0000000021fdd007 pa 0x0000000087f74000 (trapframe)

​    .. .. ..511: pte 0x0000000020001c0b pa 0x0000000080007000 (trampoline)

以上对应下面的图片。索引到页表后，要看页表中哪一项是有效的，如果那一项有效就要继续往下索引（比如说..0和..255是有效的，是否有效看flags，那他两都要往下索引，到时候比如说要trampoline的地址，那就L1去索引，目前有7个va，其中三个的L1部分可以索引到255项，得到一个新页表，其中511项是有效的（.. ..511)，然后就去查这个物理地址，得到最终页表，其中509～511项是有效的，511则是所需）。

尽管使用的虚拟地址空间是连续的，但物理地址可以不连续

想要增加stack内存（因为程序跑在stack上）可用sbrk减少heap内存（即空闲内存）

![img](assets\clip_image002-1729266274732-22.jpg)到最后，L0查pa 0x0000000087f66000得到一个页表，发现页表项中的0，1，2，3项是有效的，那么就用他们对应的物理地址加上offset得到真正所需的物理地址。

别忘了物理内存也是以pgtbl的形式存在的！！！

为什么是0～255而不是0～511呢？因为虽然说39位被硬件提供，其实设计操作系统时只用了38位，所以maxva是255

Speed up system calls 

|      |                                                   |
| ---- | ------------------------------------------------- |
|      | ![img](assets\clip_image004-1729266274732-23.jpg) |





看一下uvmunmap:函数的目的是从给定的虚拟地址(va)开始，移除指定数量(npages)的页映射。此外，它还可以选择性地释放这些映射所对应的物理内存。

系统调用加速分析：通过在用户与内核之间共享一个只读区域来加速系统调用的方法，主要针对那些不需要修改内核状态或者不频繁修改内核状态的轻量级系统调用。这种优化可以显著减少用户态与内核态之间切换的开销，因为它允许用户空间直接读取需要的信息，而无需执行完整的系统调用。

sys_fork(void): 不能被加速。fork()创建当前进程的一个副本，涉及到进程状态的复制和新进程的创建，需要内核介入。

sys_exit(void): 不能被加速。exit()终止当前进程并释放其资源，必须由内核管理。

sys_wait(void): 不能被加速。wait()等待进程改变状态，如子进程结束，需要内核调度和进程状态管理。

sys_pipe(void): 不能被加速。创建管道用于进程间通信，需要内核创建和管理管道资源。

sys_read(void): 不能被加速。读取文件或设备数据，涉及到文件系统和设备驱动，必须由内核执行。

sys_kill(void): 不能被加速。发送信号给指定进程，需要内核进行信号发送和处理。

sys_exec(void): 不能被加速。替换当前进程的映像，涉及到文件系统操作和新程序的加载，必须由内核完成。

sys_fstat(void): 不能被加速。获取文件状态，虽然主要是读取操作，但因为文件状态可能实时变化，需要内核提供最新信息。

sys_chdir(void): 不能被加速。改变当前工作目录，需要内核更新进程的目录信息。

sys_dup(void): 不能被加速。复制文件描述符，需要内核管理文件描述符表。

sys_getpid(void): 可以被加速。获取当前进程ID，进程ID在进程生命周期内不变，适合存储在初始化时的只读内存页中。

sys_sbrk(void): 不能被加速。调整进程的堆大小，涉及到内存管理，必须由内核执行。

sys_sleep(void): 不能被加速。暂停进程执行指定时间，需要内核调度。

sys_uptime(void): 不能被加速。获取系统运行时间，虽然是读取操作，但数据实时变化，不适合存储在只读内存页中。

sys_open(void): 不能被加速。打开文件，需要内核访问文件系统。

sys_write(void): 不能被加速。写入文件或设备，涉及到文件系统和设备驱动，必须由内核执行。

sys_mknod(void): 不能被加速。创建文件系统节点，如设备文件，需要内核操作文件系统。

sys_unlink(void): 不能被加速。删除文件链接，需要内核修改文件系统。

sys_link(void): 不能被加速。创建文件的硬链接，需要内核操作文件系统。

sys_mkdir(void): 不能被加速。创建目录，需要内核操作文件系统。

sys_close(void): 不能被加速。关闭文件描述符，需要内核管理文件描述符表。

总结：在这些系统调用中，只有sys_getpid(void)可以通过用户与内核之间共享的只读内存页来加速，因为它涉及的数据在进程生命周期内不会改变，适合在进程创建时一次性写入共享内存页。其他调用要么涉及到内核状态的改变，要么需要读取实时变化的数据，因此不能通过这种方式加速。



### Detecting which pages have been accessed

walk函数将当前 PTE 转换的物理地址，用作下一级页表的虚拟地址，重复流程

```c
static uint64
argraw(int n) {
    struct proc * p = myproc();
    switch (n) {

        case 0:

            return p -> trapframe -> a0;

        case 1:

            return p -> trapframe -> a1;

        case 2:

            return p -> trapframe -> a2;

        case 3:

            return p -> trapframe -> a3;

        case 4:

            return p -> trapframe -> a4;

        case 5:

            return p -> trapframe -> a5;

    }

    panic("argraw");

    return -1;

}



// Fetch the nth 32-bit system call argument.

void

argint(int n, int * ip)

{

    * ip = argraw(n);

}



// Retrieve an argument as a pointer.

// Doesn't check for legality, since

// copyin/copyout will do that.

void

argaddr(int n, uint64 * ip)

{

    * ip = argraw(n);

}
```



可见argint和argaddr都是获取系统调用的第n个参数，然后存进ip里面，记得是参数而不包括系统调用名（这个在a7寄存器）



### A kernel page table per process

xv6 原本的设计是，用户进程在用户态使用各自的用户态页表，但是一旦进入内核态（例如使用了系统调用），则切换到内核页表（通过修改 satp 寄存器，trampoline.S）。然而这个内核页表是全局共享的，也就是全部进程进入内核态都共用同一个内核态页表,本 Lab 目标是让每一个进程进入内核态后，都能有自己的独立内核页表。

释放页表的第一步是先释放页表内的内核栈，因为页表内存储的内核栈地址本身就是一个虚拟地址，需要先将这个地址指向的物理地址进行释放。然后是释放页表，直接遍历所有的页表，释放所有有效的页表项即可，这个功能可以仿照freewalk函数。由于freewalk函数将对应的物理地址也直接释放了，我们这里释放的进程的内核页表仅仅只是用户进程的一个备份，释放时仅释放页表的映射关系即可，不能将真实的物理地址也释放了。

pte_t pte = pagetable[i];

  if ((pte & PTE_V)) {

   pagetable[i] = 0;}这样子就是释放所有的页表项

内核栈在操作系统中扮演着非常重要的角色,由于 xv6 支持多核/多进程调度，同一时间可能会有多个进程处于内核态，所以需要对所有处于内核态的进程创建其独立的内核态内的栈，也就是内核栈，供给其内核态代码执行过程。主要有以下几个用途:

1中断处理

当CPU接收到中断时,它会切换到内核态执行中断处理程序。此时,中断处理程序需要使用内核栈来存储寄存器值、函数调用信息等,以保证中断处理完成后能够正确返回到原来的执行状态。

2系统调用

当用户程序发出系统调用时,CPU会从用户态切换到内核态执行相应的内核函数。内核函数也需要使用内核栈来存储上下文信息,以及临时数据。

3内核线程执行

操作系统中的很多核心功能都是通过内核线程实现的,如进程调度、文件系统操作等。这些内核线程在执行时也需要使用内核栈作为运行时栈空间。

4硬件异常处理

当CPU检测到某些硬件异常(如缺页异常、除零异常等)时,需要切换到内核态执行相应的异常处理程序,这也需要使用内核栈。

5内核数据结构

内核栈还可以用于存储一些临时的内核数据结构,如进程控制块(PCB)、文件描述符表等。

内核栈的大小通常是有限的,以防止内核代码由于栈溢出而导致系统崩溃。如果内核栈用完,内核就会触发栈溢出异常,从而采取相应的保护措施。

每个进程在内核中都有自己的内核栈,这样可以避免不同进程之间的内核栈数据相互干扰。当进程从用户态切换到内核态时,CPU会自动切换到该进程对应的内核栈。因此,内核栈是操作系统能够在内核态正常运行的重要保证。

一定要看看   [https://cloud.tencent.com/developer/article/21423](https://cloud.tencent.com/developer/article/2142321)[21](https://cloud.tencent.com/developer/article/2142321) ；

每个进程在内核中执行时使用自己的内核页表副本,这种设计有以下几个主要好处:

1. 内存保护

每个进程都有自己独立的虚拟地址空间,通过页表映射到物理内存。进程之间的内存空间是相互隔离的,从而防止一个进程非法访问另一个进程的内存数据,提高了系统的安全性和稳定性。

2. 简化内存管理

内核为每个进程维护一个单独的页表,可以方便地管理该进程的虚拟地址空间,包括分配、回收、映射等操作,而不会影响其他进程的内存。这简化了内存管理的复杂度。

3. 提高并行执行效率

由于每个进程都有自己的页表副本,内核可以并行执行多个进程,而不必担心页表的竞争条件和同步问题,从而提高了系统的并行执行效率。

4. 支持不同的内存布局

不同的进程可以有不同的内存布局(如代码段、数据段、堆栈等的位置和大小),通过为每个进程维护单独的页表,内核可以灵活地支持这种差异,而不需要使用统一的内存布局。

5. 支持内存覆盖技术

某些技术(如内存覆盖、内存共享等)需要修改进程的页表映射,如果多个进程共享同一个页表,就会影响所有进程。使用独立的页表副本可以避免这种影响,提高了灵活性。



### Simplify copyin/copyinstr

旧的copyin函数

旧的copyin函数的实现方式是:

通过循环,每次复制一个页面(通常为4KB)的数据。

在每次循环中,它会先获取用户虚拟地址srcva所在页面的起始虚拟地址va0。

然后通过walkaddr函数查询页表,获取va0对应的物理地址pa0。

如果pa0为0,说明该虚拟地址无效,函数返回错误。

计算本次需要复制的字节数n,考虑了可能跨页的情况。

使用memmove函数,从物理地址pa0+srcva在页内的偏移量处,复制n个字节到内核空间dst。

更新剩余长度len,目标地址dst,以及用户虚拟地址srcva,准备下一次循环复制。

这种实现方式的优点是,它不依赖于用户空间和内核空间的虚拟地址映射关系,可以处理任意情况下的地址翻译。它通过查询页表获取物理地址,然后进行复制,确保了安全性和可移植性。

缺点是实现相对复杂,需要处理跨页的情况,并且需要多次查询页表和进行地址翻译,效率相对较低。

新的copyin_new函数

新的copyin_new函数的实现方式是:

 

首先获取当前进程的进程控制块指针p。

检查要复制的用户虚拟地址范围是否超出了进程的合法地址空间(p->sz)。如果超出,则认为地址非法,返回错误。

直接使用memmove函数,将从用户虚拟地址srcva开始的len个字节,复制到内核空间的目标地址dst。

这种实现方式的优点是非常简单直接,只需要进行一次内存复制操作,效率较高。

缺点是它依赖于用户空间和内核空间的虚拟地址是一致映射的,也就是说,相同的虚拟地址在用户空间和内核空间中映射到相同的物理地址。如果不满足这个条件,直接使用虚拟地址进行复制就会出现问题。

另外,这种实现方式的安全性也略低于旧的copyin函数,因为它只是简单地检查了地址范围,而没有进行更细致的地址翻译和权限检查。

 

看一下视频讲解

这个lab欲使用PLIC下面所有东西来保存用户页表（这样使得内核态也可以对用户态传进来的指针（逻辑地址）进行解引用）。用户程序实际上在kernel页表（副本）中的底部。在 PLIC 之前还有一个 CLINT（核心本地中断器）的映射，该映射会与我们要 map 的程序内存冲突。从0开始映射，到clint为止

禁用user位的原因是为了debug，方便调试的时候一出错会显示page fault or kernel panic，这样之就知道是内核编程的问题而不是用户态的问题。除此之外还能ban掉执行和写权限，因为它只是读。

在proc.c中的fork中为什么是uvmcopy_not_physical(np->pagetable, np->proc_kernel_pagetable, 0, p->sz)，即为什么把fork出来的子进程的用户pagetable复制给kpagetable，而不是父进程的pagetable（因为父子是复制过来的都一样）？

如果从父进程复制，如果父进程在子进程之前退出，那么父进程页表就会被彻底清理掉，但子进程依然有指向父进程页表的指针，那么就会有无效的pte在kernel页表中。

一种设计思想：可以把disk等等放在physhop上面，建立起对物理内存的映射，然后把0～kernelbase的区域给释放了，用户空间就能有更多内存，事实上就是这么设计的。但容易受到侧通道攻击：不直接破解加密算法，而是通过分析系统实现加密算法时产生的一些间接信息（如时间、电力消耗、电磁泄露、声音等）来获取关键的密钥信息或其他敏感数据。