## 课上内容

Meltdown 是一种严重的硬件漏洞，影响了许多现代微处理器。该漏洞可以使恶意程序绕过操作系统的安全机制，从而访问本来受保护的内存区域，读取敏感信息。具体来说，Meltdown 利用了 CPU 在执行指令时的乱序执行（out-of-order execution）和推测执行（speculative execution）技术。

 

Meltdown 漏洞的关键点

乱序执行（Out-of-Order Execution）：

现代处理器为了提高性能，会对指令进行乱序执行。这意味着处理器可能会提前执行某些指令，而不按程序的顺序来执行。

推测执行（Speculative Execution）：

推测执行是指处理器在遇到分支指令（如条件跳转）时，会提前猜测哪个分支会被执行，并提前执行该分支的指令。如果猜测正确，程序执行速度就会加快；如果猜测错误，则会丢弃这些指令的结果。

缓存（Cache）：

CPU 使用缓存来加速内存访问。Meltdown 利用了缓存的特性来推测出本不应该被访问的数据。

 

Meltdown 的工作原理

Meltdown 的攻击利用了上述技术的结合，通过以下步骤实现：

触发推测执行：

恶意程序会触发 CPU 的推测执行机制，让 CPU 在执行过程中访问受保护的内存区域。这些访问通常会被操作系统的安全机制阻止，但在推测执行期间，CPU 可能不会立即检查这些权限。

侧信道攻击（Side-Channel Attack）：

虽然这些非法访问在推测执行完成后会被丢弃，但在这期间，访问的数据可能会被加载到 CPU 缓存中。通过测量内存访问时间，恶意程序可以判断哪些数据已经在缓存中，从而推测出受保护的内存内容。

![img](assets\clip_image002-1729430912618-1.jpg)

这是论文中展示攻击是如何工作的代码的简化版。如果你是攻击者，出于某种原因你可以在计算机上运行一些软件，这个计算机上有一些你想要窃取的数据。虽然你不能直接访问这些数据，但是这些数据还是位于内存中，或许是内核内存，或许是另一个进程的内存。你可以在计算机上运行一个进程，或许因为你登录到了分时共享的机器，也或许你租用了运行在主机上的服务。你可以这样发起攻击：

 

在程序中你在自己的内存中声明了一个buffer，这个buffer就是普通的用户内存且可以被正常访问。

然后你拥有了内核中的一个虚拟内存地址，其中包含了一些你想要窃取的数据。

这里的程序是C和汇编的混合，第3行代码的意思是你拥有了内核的虚拟内存地址，你从这个内存地址取值出来并保存在寄存器r2中。

第4行获取寄存器r2的低bit位，所以这里这种特定的攻击只是从内核一个内存地址中读取一个bit。

第5行将这个值乘以4096，因为低bit要么是1，要么是0，所以这意味着r2要么是4096，要么是0。

第6行中，我们就是读取前面申请的buffer，要么读取位置0的buffer，要么读取位置4096的buffer。

 

在第3行，我们读取了内核的内存地址指向的数据，我们可以直接读取内核的内存地址吗？并不能，我们相信答案是否定的。如果我们在用户空间，我们不可能直接从内核读取数据。我们知道CPU不能允许这样的行为，因为当我们使用一个内核虚拟地址时，这意味着我们会通过Page Table进行查找，而Page Table有权限标志位，我们现在假设操作系统并没有在PTE中为内核虚拟地址设置标志位来允许用户空间访问这个地址，这里的标志位在RISC-V上就是pte_u标位置。因此这里的读取内核内存地址指令必然会失败，必然会触发Page Fault。

 

然而，如论文展示的一样，这里的指令序列是有用的。虽然现在大部分场景下已经不是事实了，但是论文假设内核地址被映射到了每个用户进程的地址空间中了。也就是说，当用户代码在运行时，完整的内核PTE也出现在用户程序的Page Table中，但是这些PTE的pte_u比特位没有被设置，所以用户代码在尝试使用内核虚拟内存地址时，会得到Page Fault。在论文写的时候，所有内核的内存映射都会在用户程序的Page Table中，只是它们不能被用户代码使用而已，如果用户代码尝试使用它们，会导致Page Fault。操作系统设计人员将内核和用户内存地址都映射到用户程序的Page Table中的原因是，这使得系统调用非常的快，因为这使得当发生系统调用时，你不用切换Page Table。切换Page Table本身就比较费时，同时也会导致CPU的缓存被清空，使得后续的代码执行也变慢。所以通过同时将用户和内核的内存地址都映射到用户空间可以提升性能。但是上面的攻击依赖了这个习惯。

 

上面的代码怎么会对攻击者是有用的？如果CPU如手册中一样工作，那么这里的攻击是没有意义的，在第三行会有Page Fault。但是实际上CPU比手册中介绍的要复杂的多，而攻击能生效的原因是一些CPU的实现细节。这里攻击者依赖CPU的两个实现技巧，一个是Speculative execution（预测执行），另一个是CPU的缓存方式。

 

![img](assets\clip_image004-1729430912618-2.jpg)

现在我并没有讨论安全性，Speculative execution是一种用来提升CPU性能的技术，所以这是CPU使用的一些优化技巧。假设我们在运行这里的代码：

 

在r0寄存器保存了一个内存地址，地址可能是有效的也可能是无效的，这取决于我代码的逻辑。

 

我们假设内存中还保存了一个valid变量。在使用r0中保存地址之前，我们会先将valid从内存中加载到r1。

 

并且只有当valid等于1时，才使用r0中的地址。如果valid等于0，我们将不会使用r0中的地址。

 

如果valid等于1，我们会将r0的地址指向的内容加载到r2。

 

并对r2寄存器加1，保存在r3寄存器中。

 

在一个简单的CPU实现中，在代码的第2行，你会将valid从内存中加载到r1，这里对应了从内存中读取数据的load指令。任何一个需要从内存中读取数据的load指令都会花费2GHZ CPU的数百个CPU cycle。CPU最多可以在每个cycle执行一条指令，如果我们需要在代码的第2行等待几百个CPU cycle，那么机器会闲置数百个CPU cycle。这是一个明显的降低性能的地方，因为如果一切都正常的话，CPU可以在每个cycle内执行一条指令，而不是每几百个cycle才执行一条指令。

 

所有现在的CPU都使用了叫做branch prediction的功能。第3行的if语句是一个branch，如果我们将其转换成机器指令，我们可以发现这里有一个branch，并且这是一个带条件的branch用来测试r1寄存器是否等于1。CPU的branch prediction会至少为每个最近执行过的branch保存一个缓存，并记住这个branch是否被选中了，所以这里可能是基于上次branch的选择的预测。但是即使CPU没有足够的信息做预测，它仍然会选择一个branch，并执行其中的指令。也就是说在CPU在知道第3行代码是否为true之前，它会选择某一个branch并开始执行。或许branch选错了，但是CPU现在还不知道。

 

所以在上面的代码中，或许在第2行代码的load结束之前，也就是在知道valid变量的值之前，CPU会开始执行第4行的指令，并通过load指令读取r0指向的内存地址的内容。而r0中的内存地址或许是，也或许不是一个有效的指针。一旦load指令返回了一些内容，在代码的第5行对返回内容加1并设置到r3寄存器中。

 

或许很久之后，第2行的load指令终于完成了，现在我们知道valid变量的值。如果valid等于1，那么一切都好，如果valid等于0，CPU会取消它执行第4、5行代码的效果，并重新执行合适的分支代码，也就是第7行代码。

 

这里在确定是否应该执行之前就提前执行分支代码的行为，被称作预测执行。这是为了提升性能，如果CPU赌对了，那么它就可以超前执行一些指令，而不用等待费时的内存加载。

 

CPU中为了支持预测执行的硬件及其复杂，CPU里面有大量的设计来让这里能工作，但是没有一个设计被公开了，这些都是Intel的内部信息，并且不在手册中。所以在Meltdown Attack时，涉及到大量有关CPU是如何工作的猜测来确保攻击能生效。

 

为了能回滚误判的预测执行，CPU需要将寄存器值保存在别处。虽然代码中第4行，第5行将值保存在了r2，r3，但是实际上是保存在了临时寄存器中。如果CPU赌对了，那么这些临时寄存器就成了真实寄存器，如果赌错了，CPU会抛弃临时寄存器，这样代码第4，5行就像从来没有发生过一样。

 

在这里的代码中，我们需要考虑如果r0中是有效的指针会发生什么，如果不是有效的指针，又会发生什么。如果我们在超前执行代码第4行，并且r0中是有效的指针，那么CPU会真实的加载指针的内容到r2寄存器的临时版本中。如果r0中的指针指向的内容位于CPU的cache中，那么必然可以将内容拷贝到r2寄存器的临时版本。如果CPU的cache中没有包含数据，我并不清楚CPU是否会会从内存中读取r0中指针指向的内容。

 

对于我们来说，更有趣的一个问题是，如果r0中的指针不是一个有效的指针，会发生什么？如果r0中的指针不是一个有效的地址，并且我们在超前执行代码第4行，机器不会产生Fault。机器或许知道r0是无效的地址，并且代码第4行尝试使用一个无效的地址，但是它不能产生Page Fault，因为它不能确定代码第4行是否是一个正确的代码分支，因为有可能CPU赌错了。所以直到CPU知道了valid变量的内容，否则CPU不能在代码第4行生成Page Fault。也就是说，如果CPU发现代码第4行中r0内的地址是无效的，且valid变量为1，这时机器才会生成Page Fault。如果r0是无效的地址，且valid变量为0，机器不会生成Page Fault。所以是否要产生Page Fault的决定，可能会推迟数百个CPU cycle，直到valid变量的值被确定。

 

当我们确定一条指令是否正确的超前执行了而不是被抛弃了这个时间点，对应的技术术语是Retired。所以当我们说一个指令被超前执行，在某个时间点Retired，这时我们就知道这条指令要么会被丢弃，要么它应该实际生效，并且对机器处于可见状态。一条指令如果是Retired需要满足两个条件，首先它自己要结束执行，比如说结束了从内存加载数据，结束了对数据加1；其次，所有之前的指令也需要Retired。所以上面代码第4行在直到valid变量被从内存中加载出来且if被判定之前不能Retired，所以第4行的Retirement可能会延后数百个CPU cycle。

 

在计算机体系结构中，"retired"（或"retirement"）是一个重要的技术术语，指的是指令在 CPU 执行流水线中完成所有的执行阶段，并且其结果被正式提交（即写回到寄存器或内存中）**。当一条指令被退休（****retired****）时，这意味着它的执行是正确的且不可撤销的，它的结果可以被后续指令依赖使用。**

 

指令退休（Retirement）过程

在现代处理器中，指令的执行可以被分为几个阶段：

取指（Fetch）：从内存中取回指令。

解码（Decode）：将指令解码成处理器可以执行的操作。

执行（Execute）：在适当的执行单元中执行指令。

写回（Write-back）：将执行结果写回到寄存器或内存中。

退休（Retirement）：确认指令已经正确完成，正式提交其结果。

乱序执行和退休

现代处理器通常采用乱序执行（out-of-order execution）来提高性能。这意味着指令可以不按原始程序的顺序执行，而是根据数据依赖关系和资源可用性动态调整顺序。然而，指令退休必须按程序顺序进行（in-order retirement），确保程序的语义一致性。

退休的意义

确定性：一条指令被退休意味着它已经正确执行并且其结果被正式认可。

不可撤销：退休后的指令结果是不可撤销的，不会被丢弃。

顺序一致性：虽然指令可以乱序执行，但它们的退休顺序必须与程序顺序一致，以保持程序的正确行为。

 

例子

假设有三条指令：

1. ADD R1, R2, R3
2. LOAD R4, [R1]
3. SUB R5, R6, R7

在乱序执行的处理器中，指令 3 可能会先于指令 1 和 2 执行，因为它们之间没有数据依赖。然而，退休顺序必须是：

ADD R1, R2, R3

LOAD R4, [R1]

SUB R5, R6, R7

这样可以保证程序的正确性。

 

如果r0中的内存地址是无效的，且在Page Table中完全没有映射关系，那么我也不知道会发生什么。如果r0中的内存地址在Page Table中存在映射关系，只是现在权限不够，比如说pte_u标志位为0，那么Intel的CPU会加载内存地址对应的数据，并存储在r2寄存器的临时版本中。之后r2寄存器的临时版本可以被代码第5行使用。所以尽管r0中的内存地址是我们没有权限的内存，比如说一个内核地址，它的数据还是会被加载到r2，之后再加1并存储在r3中。之后，当代码第4行Retired时，CPU会发现这是一个无效的读内存地址行为，因为PTE不允许读取这个内存地址。这时CPU会产生Page Fault取消执行后续指令，并回撤对于r2和r3寄存器的修改。

 

所以，在这里的例子中，CPU进行了两个推测：一个是CPU推测了if分支的走向，并选择了一个分支提前执行；除此之外，CPU推测了代码第4行能够成功完成。对于load指令，如果数据在CPU缓存中且相应的PTE存在于Page Table，不论当前代码是否有权限，Intel CPU总是能将数据取出。如果没有权限，只有在代码第4行Retired的时候，才会生成Page Fault，并导致预测执行被取消。

**在预测的阶段，不论r0指向了什么地址，只要它指向了任何东西，内存中的数据会被加载到r2中。之后，当load指令Retired时才会检查权限。如果我们并没有权限做操作，所有的后续指令的效果会被取消，也就是对于寄存器的所有修改会回滚。同时，Page Fault会被触发，同时寄存器的状态就像是预测执行的指令没有执行过一样。**

这里有一些重要的术语。你可以从CPU手册中读到的，比如说一个add指令接收两个寄存器作为参数，并将结果存放在第三个寄存器，这一类设计被称为CPU的Architectural，或者通告的行为。如果你读取一个你没有权限的内存地址，你会得到一个Page Fault，你不允许读取这个内存地址，这就是一种通告的行为。CPU的实际行为被称作Micro-Architectural，CPU的通告行为与实际行为是模糊不清的。比如说CPU会悄悄的有Speculative execution。这里Architectural和Micro-Architectural的区别是Meltdown Attack的主要攻击点。

 

接下来我将介绍Micro-Architectural的另一个部分，也就是缓存。我知道大家都知道CPU有cache，但是缓存或多或少应该是也透明的。让我画个图描述一下cache，因为我认为cache与Meltdown最相关。

 

首先，你有CPU核，这是CPU的一部分，它会解析指令，它包含了寄存器，它有加法单元，除法单元等等。所以这是CPU的执行部分。

当CPU核需要执行load/store指令时，CPU核会与内存系统通信。内存系统一些cache其中包含了数据的缓存。首先是L1 data cache，它或许有64KB，虽然不太大，但是它特别的快。如果你需要的数据在L1 cache中，只通过几个CPU cycle就可以将数据取回。L1 cache的结构包含了一些线路，每个线路持有了可能是64字节的数据。这些线路是个表单，它们通过虚拟内存地址索引。如果一个虚拟内存地址在cache中，并且cache为这个虚拟内存地址持有了数据，那么实际中可以认为L1 cache中也包含了来自对应于虚拟内存地址的PTE的权限。

 

L1 cache是一个表单，当CPU核执行load指令时，首先硬件会检查L1 cache是否包含了匹配load指令的虚拟内存地址，如果有的话，CPU会直接将L1 cache中的数据返回，这样可以很快完成指令。

如果不在L1 cache，那么数据位于物理内存中，所以现在我们需要物理内存地址，这里需要Translation Lookaside Buffer（TLB），TLB是PTE的缓存。现在我们会检查load指令中的虚拟内存地址是否包含在TLB中。如果不在TLB，我们就需要做大量的工作，我们需要从内存中读取相关的PTE。让我们假设TLB中包含了虚拟内存地址对应的物理内存Page地址，我们就可以获取到所需要的物理内存地址。通常来说会有一个更大的cache（L2 cache），它是由物理内存地址索引。

现在通过TLB我们找到了物理内存地址，再通过L2 cache，我们有可能可以获取到数据。如果我们没有在L2 cache中找到物理内存地址对应的数据。我们需要将物理内存地址发送给RAM系统。这会花费很长的时间，当我们最终获得了数据时，我们可以将从RAM读取到的数据加入到L1和L2 cache中，最终将数据返回给CPU核。

![img](assets\clip_image006-1729430912618-3.jpg)

以上就是CPU的cache。如果L1 cache命中的话可能只要几个CPU cycle，L2 cache命中的话，可能要几十个CPU cycle，如果都没有命中最后需要从内存中读取那么会需要几百个CPU cycle。一个CPU cycle在一个2GHZ的CPU上花费0.5纳秒。所以拥有cache是极其有利的，如果没有cache的话，你将会牺牲掉几百倍的性能。所以cache对于性能来说是非常关键的。

 

在Meltdown Attack的目标系统中，如果我们运行在用户空间，L1和L2 cache可以既包含用户数据，也包含内核数据。L2 cache可以包含内核数据因为它只是物理内存地址。L1 cache有点棘手，因为它是虚拟内存地址，当我们更换Page Table时，L1 cache的内容不再有效。因为更换Page Table意味着虚拟内存地址的意义变了，所以这时你需要清空L1 cache。不过实际中会有更多复杂的细节，可以使得你避免清空L1 cache。

 

论文中描述的操作系统并没有在内核空间和用户空间之间切换的时候更换Page Table，因为两个空间的内存地址都映射在同一个Page Table中了。这意味着我们不必清空L1 cache，也意味着L1 cache会同时包含用户和内核数据，这使得系统调用更快。如果你执行系统调用，当系统调用返回时，L1 cache中还会有有用的用户数据，因为我们在这个过程中并没与更换Page Table。所以，当程序运行在用户空间时，L1 cache中也非常有可能有内核数据。L1 cache中的权限信息拷贝自TLB中的PTE，如果用户空间需要访问内核内存数据，尽管内核数据在L1 cache中，你也不允许使用它，如果使用的话会触发Page Fault。

 

尽管Micro-Architectural的初衷是完全透明，实际中不可能做到，因为Micro-Architectural优化的意义在于提升性能，所以至少从性能的角度来说，它们是可见的。也就是说你可以看出来你的CPU是否有cache，因为如果没有的话，它会慢几百倍。除此之外，如果你能足够精确测量时间，那么在你执行一个load指令时，如果load在几个CPU cycle就返回，数据必然是在cache中，如果load在几百个CPU cycle返回，数据可能是从RAM中读取，如果你能达到10纳秒级别的测量精度，你会发现这里区别还是挺大的。所以从性能角度来说，Micro-Architectural绝对不是透明的。我们现在讨论的分支预测，cache这类功能至少通过时间是间接可见的。

 

所以尽管Micro-Architectural设计的细节都是保密的，但是很多人对它都有强烈的兴趣，因为这影响了很多的性能。比如说编译器作者就知道很多Micro-Architectural的细节，因为很多编译器优化都基于人们对于CPU内部工作机制的猜测。实际中，CPU制造商发布的优化手册披露了一些基于Micro-Architectural的技巧，但是他们很少会介绍太多细节，肯定没有足够的细节来理解Meltdown是如何工作的。所以Micro-Architectural某种程度上说应该是透明的、隐藏的、不可见的，但同时很多人又知道一些随机细节。

 

通常你看到的要么是三级cache，或者是两级cache但是L2 cache是合并在一起的（即多个cpu共用L2 cache）。典型场景下，L2和L3是物理内存地址索引，L1是虚拟内存地址索引。

 

学生提问：拥有物理内存地址的缓存有什么意义？

Robert教授：如果同一个数据被不同的虚拟内存地址索引，虚拟内存地址并不能帮助你更快的找到它。而L2 cache与虚拟内存地址无关，不管是什么样的虚拟内存地址，都会在L2 cache中有一条物理内存地址记录。

学生提问：MMU和TLB这里位于哪个位置？

Robert教授：我认为在实际中最重要的东西就是TLB，并且我认为它是与L1 cache并列的。如果你miss了L1 cache，你会查看TLB并获取物理内存地址。MMU并不是一个位于某个位置的单元，它是分布在整个CPU上的。

Page Table的映射如果没有在TLB中命中的话，还是要走到内存来获取数据，对吧？

Robert教授：从L2 cache的角度来说，TLB miss之后的查找Page Table就是访问物理内存，所以TLB需要从内存中加载一些内存页，因为这就是加载内存，这些内容可以很容易将Page Table的内容缓存在L2中。



为什么Cache与Meltdown相关呢？

所以如果你是用户代码，你可以使用属于你的用户空间内存，并且你现在要调用一个你自己的函数，你可以使用Flush and Reload来知道你刚刚执行的函数是否使用了某个属于你自己的内存。你不能直接使用这种技术来获取其他进程的私有内存。进程之间有时候会共享内存，你还是可以访问这部分共享的内存。所以Flush and Reload回答了这个问题，特定的函数是否使用了特定内存地址？它的具体工作步骤如下：

 

第一步，假设我们对地址X感兴趣，我们希望确保Cache中并没有包含位于X的内存数据。实际中，为了方便，Intel提供了一条指令，叫做clflush，它接收一个内存地址作为参数，并确保该内存地址不在任何cache中。这超级方便，不过即使CPU并没有提供这样的指令，实际中也有方法能够删除Cache中的数据，举个例子，如果你知道Cache有64KB，那么你load 64KB大小的随机内存数据，这些数据会被加载到Cache中，这时Cache中原本的数据会被冲走，因为Cache只有64KB大小。所以即使没有这个好用的指令，你仍然可以清空Cache中的所有数据。

 

第二步，如果你对某段可能使用了内存地址X的代码感兴趣，你可以调用这个函数，先不管这个函数做了什么，或许它使用了内存地址X，或许没有。

 

现在，你想要知道X是否在Cache中，如果是的话，因为在第一步清空了Cache，必然是因为第二步的函数中load了这个内存地址。所以你现在想要执行load，但是你更想知道load花费了多长时间，而且我们这里讨论的是纳秒级别的时间，比如5个纳秒或者100个纳秒，那么我们该怎样达到这种测量精度呢？这是个困难的任务。Intel CPU会提供指令来向你返回CPU cycle的数量，这被称为rdtsc。所以这里我们会执行rdtsc指令，它会返回CPU启动之后总共经过了多少个CPU cycle。如果是2GHZ的CPU，这意味着通过这个指令我们可以得到0.5纳秒的测量精度。

 

现在我们会将内存地址X的数据加载到junk对象中。

 

然后再通过rdtsc读取时间。如果两次读取时间的差是个位数，那么上一步的load指令走到了cache中，也就是第二步的函数中使用了内存地址X的数据。如果两次读取时间的差别超过100，这意味着内存地址X不在cache中，虽然这并不绝对，但是这可能代表了第二步的函数中并没有使用内存X的数据。因为函数中可能使用了内存地址X，然后又用了其他与X冲突的数据，导致内存地址X又被从cache中剔除了。但是对于简单的情况，如果两次时间差较大那么第二步的函数没有使用内存地址X，如果两次时间差较小那么第二步函数使用了内存地址X。



![img](assets\clip_image008-1729430912618-4.jpg)

**Low bit was probably a 0（图中有错误！！！！！！！！)**

首先我们声明了一个buffer，现在我们只需要从内核中窃取1个bit的数据，我们会将这个bit乘以4096，所以我们希望下面的Flush and Reload要么看到buffer[0]在cache中，要么看到buffer[4096]在cache中。为什么要有这么的大的间隔？是因为硬件有预获取。如果你从内存加载一个数据，硬件极有可能会从内存中再加载相邻的几个数据到cache中。所以我们不能使用两个非常接近的内存地址，然后再来执行Flush and Reload，我们需要它们足够的远，这样即使有硬件的预获取，也不会造成困扰。所以这里我们将两个地址放到了两个内存Page中（注，一个内存Page 4096）。

 

现在的Flush部分直接调用了clflush指令（代码第4第5行），来确保我们buffer中相关部分并没有在cache中。

我们将会在第10行执行load指令，它会load一个内核内存地址，所以它会产生Page Fault。但是我们期望能够在第10行指令Retired之前，也就是实际的产生Page Fault并取消这些指令效果之前，再预测执行（Speculative execution）几条指令。如果代码第10行在下面位置Retired，那么对我们来说就太早了。实际中我们需要代码第13行被预测执行，这样才能完成攻击。所以我们希望代码第10行的load指令尽可能晚的Retired，这样才能推迟Page Fault的产生和推迟取消预测执行指令的效果。因为我们知道一个指令只可能在它之前的所有指令都Retired之后，才有可能Retired。所以在代码第7行，我们可以假设存在一些非常费时的指令，它们需要很长时间才能完成。或许要从RAM加载一些数据，这会花费几百个CPU cycle；或许执行了除法，或者平方根等。这些指令花费了很多时间，并且很长时间都不会Retired，因此也导致代码第10行的load很长时间也不会Retired，并给第11到13行的代码时间来完成预测执行。

 

现在假设我们已经有了内核的一个虚拟内存地址，并且要执行代码第10行。我们知道它会生成一个Page Fault，但是它只会在Retired的时候才会真正的生成Page Fault。我们设置好了使得它要过一会才Retired。因为代码第10行还没有Retired，并且在Intel CPU上，即使你没有内存地址的权限，数据也会在预测执行的指令中被返回。这样在第11行，CPU可以预测执行，并获取内核数据的第0个bit。第12行将其乘以4096。第13行是另一个load指令，load的内存地址是buffer加上r2寄存器的内容。我们知道这些指令的效果会被取消，因为第10行会产生Page Fault，所以对于r3寄存器的修改会被取消。但是尽管寄存器都不会受影响，代码第13行会导致来自于buffer的部分数据被加载到cache中。取决于内核数据的第0bit是0还是1，第13行会导致要么是buffer[0]，要么是buffer[4096]被加载到cache中。之后，尽管r2和r3的修改都被取消了，cache中的变化不会被取消，因为这涉及到Micro-Architectural，所以cache会被更新。

 

第15行表示最终Page Fault还是会发生，并且我们需要从Page Fault中恢复。用户进程可以注册一个Page Fault Handler（注，详见Lec17），并且在Page Fault之后重新获得控制。论文还讨论了一些其他的方法使得发生Page Fault之后可以继续执行程序。

 

现在我们需要做的就是弄清楚，是buffer[0]还是buffer[4096]被加载到了cache中。现在我们可以完成Flush and Reload中的Reload部分了。第18行获取当前的CPU时间，第19行load buffer[0]，第20行再次读取当前CPU时间，第21行load buffer[4096]，第22行再次读取当前CPU时间，第23行对比两个时间差。哪个时间差更短，就可以说明内核数据的bit0是0还是1。如果我们重复几百万次，我们可以扫描出所有的内核内存。

 

在这个例子中，我们只读了一个bit，有没有一些其他的修改使得我们可以读取一整个寄存器的数据？

Robert教授：有的，将这里的代码运行64次，每次获取1个bit。

学生提问：为什么不能一次读取64bit呢？

Robert教授：如果这样的话，buffer需要是2^64再乘以4096，我们可能没有足够的内存来一次读64bit。或许你可以一次读8个bit，然后buffer大小是256*4096。论文中有相关的，因为这里主要的时间在第17行到第24行，也就是Flush and Reload的Reload部分。如果一次读取一个字节，那么找出这个字节的所有bit，需要256次Reload，每次针对一个字节的可能值。如果一次只读取一个bit，那么每个bit只需要2次Reload。所以一次读取一个bit，那么读取一个字节只需要16次Reload，一次读取一个字节，那么需要256次Reload。所以论文中说一次只读取一个bit会更快，这看起来有点反直觉，但是又好像是对的。

 

这里的代码会运行在哪？会运行在特定的位置吗？

Robert教授：这取决于你对于机器有什么样的权限，并且你想要窃取的数据在哪了。举个例子，你登录进了Athena（注，MIT的共享计算机系统），机器上还有几百个其他用户 ，然后你想要窃取某人的密码，并且你很有耐心。在几年前Athena运行的Linux版本会将内核内存映射到每一个用户进程的地址空间。那么你就可以使用Meltdown来一个bit一个bit的读取内核数据，其中包括了I/O buffer和network buffer。如果某人在输入密码，且你足够幸运和有耐心，你可以在内核内存中看见这个密码。实际中，内核可能会映射所有的物理内存，比如XV6就是这么做的，这意味着你或许可以使用Meltdown在一个分时共享的机器上，读取所有的物理内存，其中包括了所有其他进程的内存。这样我就可以看到其他人在文本编辑器的内容，或者任何我喜欢的内容。这是你可以在一个分时共享的机器上使用Meltdown的方法。其他的场景会不太一样。

 

很多操作系统在这篇论文发表之后数周内就推出的一个快速修复，这是一个叫做KAISER，现在在Linux中被称为KPTI的技术（Kernel page-table isolation）。这里的想法很简单，也就是不将内核内存映射到用户的Page Table中，相应的就像XV6一样，在系统调用时切换Page Table。所以在用户空间时，Page Table只有用户内存地址的映射，如果执行了系统调用，会有类似于XV6中trampoline的机制，切换到拥有内核内存映射的另一个Page Table中，这样才能执行内核代码。这会导致Meltdown不能工作，因为现在你会切换Page Table。

 

KAISER的缺点是，系统调用的代价更高了，因为如果不做任何事情的话，切换Page Table会导致TLB被清空，因为现在TLB中的映射关系都是前一个Page Table的。同时也会导致L1 cache被清空，因为其中对应的虚拟内存地址对于新的Page Table也没有意义了。在一些机器上，切换Page Table会使得系统调用明显变慢。

 

最近的CPU拥有叫做PCID（process-context identifiers）的技术，它可以帮助你在切换Page Table时避免清空Cache，尽管它还是要花费一些时间。