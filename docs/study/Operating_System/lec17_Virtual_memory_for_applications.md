## 课前内容

操作系统提供的VM原语（**给****user space**）：

trap 在**用户模式**设置page-fault处理程序

prot 1 移除某个page的一些权限

prot N 移除某批pages的一些权限

unprot 为某个page添加一些权限

dirty 返回自上次调用以来被修改过的pages

map2 在同一个地址空间中, 将同一个物理page映射到两个不同的虚拟地址, 并设置不同的访问权限（因为在多线程并发的时候, 需要规定一些内存页只能被一些线程访问, 使用map2就可以通过控制线程访问不同虚拟地址的page来实现.）

 

在使用Prot1时，你需要修改PTE的bit位，并且在Prot1的结束时，需要清除TLB（注，详见4.4 Translation Lookaside Buffer），而清除TLB比较费时。如果能对所有需要修改的内存Page集中清理一次TLB，就可以将成本分摊。所以ProtN等效于修改PTE的bit位N次，再加上清除一次TLB。如果执行了N次Prot1，那就是N次修改PTE的bit位，再加上清除N次TLB，所以ProtN可以减少清除TLB的次数，进而提升性能。

 

Concurrenct garbage collection

mutator: 指的是用户线程的意思

collector: 回收线程, 当mutator申请内存不足的时候就会执行它

from-space & to-space, 算法将heap分为了两部分, mutator只能看到to-space中的内容

scanned & unscanned 看起来是两个指针

需要强调的是用户进程能看到的空间是tospace，flip操作指的是交换from-space和to-space

先介绍stop and copy collection这个垃圾回收机制

这种算法将堆内存分为两个相等的部分：活动区域（From Space）和空闲区域（To Space）。在进行垃圾回收时，算法会停止应用程序的执行（Stop），将所有活动对象从活动区域复制（Copy）到空闲区域，并交换两块区域的角色。

工作原理：

1内存分区：

将堆内存分为两个相等的部分：From Space 和 To Space。

2停止程序（Stop）：

停止应用程序的执行，确保内存不再发生变化。

3标记活动对象：

从根对象（如栈、全局变量等）开始，标记所有可达的活动对象。

4复制活动对象（Copy）：

 

将所有标记的活动对象从 From Space 复制到 To Space。

更新对象的引用，确保所有引用指向新的位置。

5交换区域：

复制完成后，交换 From Space 和 To Space 的角色。

原来的 To Space 现在变成新的 From Space，原来的 From Space 变成新的 To Space，并且被完全清空。

优点

简化内存分配：内存分配变得非常简单，只需从 To Space 中顺序分配。

消除内存碎片：通过复制活动对象，内存被连续使用，消除了碎片问题。

高效的内存管理：只需扫描一次活动对象，回收效率高。

缺点

内存利用率低：因为堆内存被分为两半，有一半的内存始终处于闲置状态，内存利用率较低。

暂停时间长：每次进行垃圾回收时，需要停止应用程序，可能会导致较长的暂停时间，影响程序的响应性。

示例

假设堆内存为 8 个单元：

From Space: [A, B, C, D]

To Space:  [_, _, _, _]

进行垃圾回收时，假设 A 和 C 是活动对象：

 

标记活动对象：

活动对象：A, C

 

复制活动对象：

From Space: [_, B, _, D]

To Space:  [A, _, C, _]

 

更新引用：

所有指向 A 和 C 的引用更新到新的位置。

交换区域：

 

From Space: [A, _, C, _]

To Space:  [_, B, _, D] (清空)

最终，活动对象 A 和 C 被复制到新的空间，原来的空间被清空，可以重新使用。

 

Baker算法改进的工作如下:

![img](assets\clip_image002-1729430046048-1.jpg)

一旦复制完roots后就返回到用户进程(看到这里笔者感觉应该类似于Copy-On-Write), 时刻记住, 用户进程看到的内存始终是to-space:

![img](assets\clip_image004-1729430046048-2.jpg)

这个时候就用到操作系统的原语了：map2

Baker's Algorithm相对于原本的Stop-and-Copy算法有以下几个显著的改进和优势：

1减少停顿时间

Stop-and-Copy：

在垃圾回收过程中，需要完全停止应用程序的执行，直到回收完成。这种全停顿方式会导致应用程序在回收期间无法响应用户请求，影响用户体验。

Baker's Algorithm：

使用一种渐进式回收方式，即程序可以在回收过程中继续执行。虽然会有一些额外的开销，但整体停顿时间大大减少，有利于提高程序的响应性。

2分代垃圾回收

Stop-and-Copy：

主要针对整个堆进行回收，没有对对象的生命周期进行区分。

Baker's Algorithm：

采用分代回收的策略，将对象根据其生命周期分为不同的代（如年轻代和老年代）。这种策略的优势在于，大多数对象的生命周期较短，可以快速回收年轻代的对象，而较少频繁地处理老年代的对象，从而提高了回收效率。

 

Shared virtual memory

共享虚拟内存是虚拟内存的一种应用，允许多个进程共享同一块虚拟内存区域。这块共享区域在多个进程的地址空间中映射到相同的物理内存地址。

对于共享的地址空间中的page, 被标记为Read-only的page可以同时在每个cpu的缓存中存在副本, 如果一个cpu正在修改某一个page, 那么必须告知其他cpu这件事,以保持数据一致性.

工作原理

1映射共享内存区域：

操作系统在不同进程的虚拟地址空间中映射一块共享的内存区域。这些进程对该区域的访问都会指向同一块物理内存。

2访问同步：

为了避免竞争条件和数据不一致问题，通常需要对共享内存区域的访问进行同步控制。例如，通过互斥锁（Mutex）或信号量（Semaphore）来实现同步。

3内存保护：

共享内存区域仍然受虚拟内存保护机制的约束。不同进程可以拥有不同的访问权限（读、写、执行）。

优点

内存效率：多个进程共享同一块物理内存，减少了内存使用量。

数据共享：进程间可以高效地共享数据，不需要通过文件或消息传递。

性能提升：通过共享内存，可以减少数据复制和进程间通信的开销。

缺点

同步复杂性：需要额外的同步机制来保证数据一致性，增加了编程复杂度。

安全性问题：不当的内存共享可能导致安全漏洞，如数据泄露或非法访问。

 

Concurrent checkpointing

在fs中，加检查点就是将日志中的事务（元数据和数据更新）写入磁盘的最终位置上。在这里checkpointing就是将线程(进程)在内存中的数据拷贝到磁盘中，在我们拷贝的过程中当前被加检查点(be checkpointed)的线程被处于阻塞状态. Concurrent checkpointing则是利用page fault保护机制来让被加检查点线程不必被阻塞(或者说不必花费大量的时间来等待I/O).

 

具体来说, 被加检查点的线程被暂时被阻塞, 然后该线程的所在的整个地址空间的pages都被设置为Read only(这个操作应该是由加检查点的线程来做), 这个时刻, 会在后台运行一个copying thread, 同时重启被加检查点的线程, copying thread会在后台把地址空间被加检查点线程的pages复制到内存中另一块独立的区域, 每完成一份page的复制就会恢复被加检查点线程的地址空间中page权限为read/write.

![img](assets\clip_image006-1729430046048-3.jpg)

线程T1为被加检查点的线程, 如果T1试图写数据到其地址空间, 那么就会触发page fault, 这个时候就会通知后台运行的copying thread立刻复制该page并恢复权限, 然后重启写操作.（copy完出现pagefault的那一页（因为它是readonly，但现在要write它）到内存中另一个地方后，就会把那一页的权限给改变，之后write again)

 

Generational garbage collection

该收集方式是建立在以下两个对程序运行时对象生命周期的观察的总结之上:

 

新创建的对象往往更容易成为garbage.

新创建的对象倾向于指向更早的对象.

这都是一些常见的习惯, 我们往往会创建一些临时的变量之类的来作为计算的过渡, 很快这些变量就会被废弃成为garbage, 创建新对象的时候往往会初始化为更早的对象的数据结构, 即旧数据的复用.

 

分代垃圾回收的基本原理

新生代(Young Generation):大多数新创建的对象都被分配在新生代。新生代通常占用较小的内存空间,垃圾回收频繁发生在新生代。新生代常被划分为一个Eden区和两个Survivor区。

 

老年代(Old Generation):在新生代中经历了多次垃圾回收后仍然存活的对象会被晋升(Promote)到老年代。老年代占用较大的内存空间,垃圾回收发生的频率低于新生代。

 

对象晋升:当对象在新生代中经历了一定次数的垃圾回收后依然存活,就会被晋升到老年代。另外如果Survivor区空间不足,也会将对象提前晋升到老年代。

 

Persistent stores: 在持久化存储中,page fault可以用来处理对尚未加载到内存中的数据的访问请求.当程序试图访问这些数据时,会触发页面错误,操作系统会将数据从磁盘加载到内存中,然后继续执行程序.这种方法可以使程序看起来像是在访问常驻内存的数据,实际上数据是在需要时才加载到内存中的.

Extending addressability: 扩展寻址能力是虚拟内存系统的一个重要功能.在这种系统中,程序可以访问的地址空间远大于实际的物理内存大小.当程序试图访问一个尚未映射到物理内存的虚拟地址时,会触发页面错误.操作系统会找到这个虚拟地址对应的数据,可能在磁盘上,将其加载到物理内存中,然后更新虚拟地址到物理地址的映射,使程序可以继续执行.

Data-compression paging: 数据压缩分页的核心思想是:对内存页面进行压缩,然后以压缩后的格式存储在内存和磁盘中。这样可以在同样大小的物理空间中存储更多的页面数据。在数据压缩分页中,页面错误可以用来处理对压缩数据的访问请求.当程序试图访问一个被压缩的页面时,会触发页面错误.操作系统会将页面的压缩数据解压缩到内存中,然后程序可以继续访问这个页面.这种方法可以在内存紧张的情况下,通过牺牲一些CPU时间来节省内存空间.

Heap overflow detection: 在堆溢出检测中,页面错误可以用来检测堆的溢出.通常,操作系统会在堆的顶部保留一个未映射的页面,称为"哨兵页面".当程序试图分配超出堆大小的内存时,会试图访问这个哨兵页面,从而触发页面错误.操作系统可以捕获这个错误,从而检测到堆的溢出.

 

当main函数调用func1,func1再调用func2时,栈的变化如下（结合虚拟内存那一章的图去想）:

![img](assets\clip_image008-1729430046048-4.jpg)![img](assets\clip_image010-1729430046048-5.jpg)

高地址往上是堆。每个栈帧（包含sp和fp)如图所示

 

 ## 课上内容

mmap 是一种在内存管理中的技术，用于将文件或设备映射到进程的地址空间中（虚拟内存！！！）。这种映射技术使进程可以直接访问文件内容，就像在操作内存一样，从而提高了文件I/O的效率和灵活性。

 

基本概念

mmap 函数在 UNIX 类操作系统中非常常见（如 Linux、macOS），它的基本功能包括：

将文件的一部分或全部映射到内存。

支持读写操作。

提供文件与内存之间的同步。

常用函数和参数

 

在 C 语言中，mmap 的函数定义通常如下：

void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);

addr：映射的首地址，通常设为 NULL 让内核选择地址。

length：映射的长度。

prot：保护标志，定义页的权限，如 PROT_READ（只读）和 PROT_WRITE（可写）。

flags：标志，确定映射对象和共享/私有属性，如 MAP_SHARED（共享）和 MAP_PRIVATE（私有）。

fd：文件描述符，指向要映射的文件。

offset：文件映射的起始偏移量，需为 PAGE_SIZE 的整数倍。

 

普通的文件访问方式通常指的是使用标准的文件I/O函数来读取和写入文件内容。这些函数在C语言标准库和许多其他编程语言中都广泛使用。以下是使用C语言的标准文件I/O函数进行文件访问的示例和解释。

 

在C语言中，常用的文件I/O函数包括：

fopen：打开文件。

fclose：关闭文件。

fread：从文件读取数据。

fwrite：向文件写入数据。

fseek：设置文件指针位置。

ftell：获取文件指针当前位置。

fprintf / fscanf：格式化写入/读取。

 

假设有一个大文件 data.txt，其中包含了大量的数据。我们需要读取这个文件，并统计其中的某个字符（例如，字符 'a'）出现的次数。

 

使用标准文件I/O的实现

首先，使用标准的文件I/O函数来实现这一需求：头文件没写

int main() {

  // 打开文件

  FILE *file = fopen("data.txt", "r");

  if (file == NULL) {

​    perror("Error opening file");

​    return EXIT_FAILURE;

  }

 

  // 统计字符'a'出现的次数

  int count = 0;

  char ch;

  while ((ch = fgetc(file)) != EOF) {

​    if (ch == 'a') {

​      count++;

​    }

  }

 

  // 输出结果

  printf("The character 'a' appeared %d times.\n", count);

  // 关闭文件

  fclose(file);

  return EXIT_SUCCESS;

}通过 fopen 打开文件，通过 fclose 关闭文件。

逐字符读取：使用 fgetc 函数逐个读取文件中的字符，并统计字符 'a' 的出现次数。

 

使用 mmap 文件映射方式来实现同样的需求：

int main() {

  // 打开文件

  int fd = open("data.txt", O_RDONLY);

  if (fd == -1) {

​    perror("Error opening file");

​    return EXIT_FAILURE;

  }

 

  // 获取文件大小

  struct stat sb;

  if (fstat(fd, &sb) == -1) {

​    perror("Error getting file size");

​    close(fd);

​    return EXIT_FAILURE;

  }

  size_t filesize = sb.st_size;

 

  // 将文件映射到内存

  char *mapped = mmap(NULL, filesize, PROT_READ, MAP_PRIVATE, fd, 0);

  if (mapped == MAP_FAILED) {

​    perror("Memory mapping failed");

​    close(fd);

​    return EXIT_FAILURE;

  }

 

  // 统计字符'a'出现的次数

  int count = 0;

  for (size_t i = 0; i < filesize; ++i) {

​    if (mapped[i] == 'a') {

​      count++;

​    }

  }

  // 输出结果

  printf("The character 'a' appeared %d times.\n", count);

  // 清理

  if (munmap(mapped, filesize) == -1) {

​    perror("Error unmapping memory");

  }

  close(fd);

  return EXIT_SUCCESS;

}

标准文件I/O：逐字符读取文件时，每次读取都需要系统调用，开销较大，处理大文件时效率较低。

mmap 映射：一次性将文件映射到内存，可以直接访问内存中的文件内容，效率更高，适合处理大文件和需要频繁访问的场景。

![img](assets\clip_image002-1729430110986-11.jpg)

VMA（Virtual Memory Area，虚拟内存区域）是操作系统中的一个概念，用于描述进程地址空间中的一段连续的虚拟内存（用一个结构体表示）。每个VMA具有相同的内存访问权限和属性。VMA在现代操作系统中起着重要的作用，特别是在内存管理和文件映射方面。

 

VMA的主要属性

起始地址和结束地址：定义了这段虚拟内存区域的范围。

权限：描述这段内存区域的访问权限，如只读、可读写、可执行等。

映射类型：说明这段内存区域是否映射到物理内存、文件或其他设备。

相关文件：如果VMA是文件映射的一部分，它会包含一个指向该文件的指针。

偏移量（offset）：如果该 VMA 映射的是一个文件的一部分，偏移量表示文件的哪一部分映射到该内存区域。

区域属性（flags）：描述该区域的属性，如是否共享（shared）、是否匿名（anonymous，即不与文件关联）。

 

 

 

 

​    **今天论文中的核心观点是，用户应用程序也应该从灵活的虚拟内存中获得收益，也就是说用户应用程序也可以使用虚拟内存，具体理由见下面第二次黑体标题。**用户应用程序本身就是运行在虚拟内存之上，我们这里说的虚拟内存是指：**User Mode****或者应用程序想要使用与内核相同的机制，来产生Page Fault****并响应Page Fault**（注，详见Lec08，内核中几乎所有的虚拟内存技巧都基于Page Fault）。也就是说User Mode需要能够修改PTE的Protection位（注，Protection位是PTE中表明对当前Page的保护，对应了4.3中的Writeable和Readable位）或者Privileged level。

TLB是Translation Lookaside Buffer的简称，也叫做“地址转换后援缓冲器”或“快表”。它是MMU的一部分，存储了当前最可能被访问到的页表项的副本，用于加速虚拟地址到物理地址的转换。

 

在XV6的内核中包含了所有的可用的虚拟内存的机制，但是并没有以系统调用的形式将它们暴露给用户空间。论文的观点是，任何一个好的操作系统都应该以系统调用的形式提供以上特性（即在首页就提到的那些原语），以供应用程序使用。

 

**支持应用程序使用虚拟内存的系统调用：**

mmap系统调用有许多令人眼花缭乱的参数（注，mmap的具体说明可以参考man page）：

第一个参数是一个你想映射到的特定地址，如果传入null表示不指定特定地址，这样的话内核会选择一个地址来完成映射，并从系统调用返回。

第二个参数是想要映射的地址段长度len。

第三个参数是Protection bit，例如读写R|W。

第四个参数是flags，MAP_PRIVATE是其中一个值，在mmap文件的场景下，MAP_PRIVATE表明更新文件不会写入磁盘，只会更新在内存中的拷贝，例如，在文本编辑器中，加载文件内容到内存，可以自由编辑内容。在最终决定保存修改之前，所有更改只影响内存而不触及原始文件。

第五个参数是传入的对象，在上面的例子中就是文件描述符。

第六个参数是offset。

通过上面的系统调用，可以将文件描述符指向的文件内容，从起始位置加上offset的地方开始，映射到特定的内存地址（如果指定了的话），并且连续映射len长度。这使得你可以实现Memory Mapped File，你可以将文件的内容带到内存地址空间，进而只需要方便的通过普通的指针操作，而不用调用read/write系统调用，就可以从磁盘读写文件内容。这是一个方便的接口，可以用来操纵存储在文件中的数据结构。

对应mmap还有一个系统调用munmap，它使得你可以移除一个地址或者一段内存地址的映射关系。

 

mprotect系统调用（注，详见man page）。当你将某个对象映射到了虚拟内存地址空间，你可以修改对应虚拟内存的权限，这样你就可以以特定的权限保护对象的一部分，或者整个对象。

![img](assets\clip_image004-1729430110986-12.jpg)

最后一个系统调用是sigaction，它本质上是用来处理signal。它使得应用程序可以设置好一旦特定的signal发生了，就调用特定的函数。可以给它传入函数f作为特定signal的handler。在Page Fault的场景下，生成的signal是segfault。通常来说当发生segfault时，应用程序会停止运行并crash。但是如果应用程序为segfault signal设置了handler，发生segfault时，应用程序不会停止，相应的handler会被内核调用，然后应用程序可以在handler中响应segfault。当内核发现Page Fault时，或许会通过修复Page Table来使得应用程序还能继续执行。与内核响应Page Fault的方式类似，在这里的handler中或许会调用mprotect来修改内存的权限来避免segfault，这样应用程序的指令就可以恢复运行。

 

trap对应的是sigaction系统调用

Prot1，ProtN和Unprot可以使用mprotect系统调用来实现。mprotect足够的灵活，你可以用它来修改一个Page的权限，也可以用它来修改多个Page的权限。当修改多个Page的权限时，可以获得只清除一次TLB的好处。

查看Page的Dirty位要稍微复杂点，并没有一个直接的系统调用实现这个特性，不过你可以使用一些技巧完成它，我稍后会介绍它。

map2也没有一个系统调用能直接对应它，通过多次调用mmap，你可以实现map2特性。

 

**虚拟内存系统如何支持用户应用程序？（实现）**

第一个是虚拟内存系统为了支持这里的特性，具体会发生什么？

在现代的Unix系统中，地址空间是由硬件Page Table来体现的，在Page Table中包含了地址翻译。但是通常来说，地址空间还包含了一些操作系统的数据结构，这些数据结构与任何硬件设计都无关，它们被称为Virtual Memory Areas（VMAs）（即地址空间=pgtb+vmas)。VMA会记录一些有关连续虚拟内存地址段的信息。在一个地址空间中，可能包含了多个section，每一个section都由一个连续的地址段构成，对于每个section，都有一个VMA对象。连续地址段中的所有Page都有相同的权限，并且都对应同一个对象VMA例如一个进程的代码是一个section，数据是另一个section，它们对应不同的VMA。

VMA的定义：VMA是对进程虚拟地址空间中某段连续区域的描述。这些区域可能包括代码段、数据段、堆栈和堆等。

VMA记录的信息（用一个结构体表示）

连续虚拟内存地址段：一个VMA对象对应虚拟地址空间中的一个连续区段。

权限和属性：VMA记录了这个区段的权限（例如，可读、可写、可执行）和其他属性。

关联对象：VMA还记录了与这个区段关联的对象，例如文件映射、匿名内存等。

地址空间中的多个Section

Section：地址空间可以被分割成多个Section（区段），每一个Section对应一段连续的虚拟地址。

同一对象VMA：每一个Section具有相同的权限并对应同一个VMA对象。

假设有一个进程，它的虚拟地址空间包括以下几部分：

 

代码段（Text Segment）：

地址区间：0x00400000 - 0x00500000

权限：只读和可执行

VMA对象：VMA1

 

数据段（Data Segment）：

地址区间：0x00500000 - 0x00600000

权限：可读和可写

VMA对象：VMA2

 

堆（Heap）：

地址区间：0x00600000 - 0x00700000（动态扩展）

权限：可读和可写

VMA对象：VMA3

 

栈（Stack）：

地址区间：从高地址向低地址扩展，例如0xBFFFFFFF - 0xBFF00000

权限：可读和可写

VMA对象：VMA4

第二个部分也就是User level trap是如何实现的？我们假设一个PTE被标记成invalid或者只读，而你想要向它写入数据。这时，CPU会跳转到kernel中的固定程序地址，也就是XV6中的trampoline代码。kernel会保存应用程序的状态，在XV6中是保存到trapframe。之后再向虚拟内存系统查询，现在该做什么呢？虚拟内存系统或许会做点什么，例如在lazy lab和copy-on-write lab中，trap handler会查看Page Table数据结构。而在我们的例子中会查看VMA，并查看需要做什么。举个例子，如果是segfault，并且应用程序设置了一个handler来处理它，那么

segfault事件会被传播到用户空间

并且通过一个**到**用户空间的upcall在用户空间运行handler

在handler中或许会调用mprotect来修改PTE的权限

之后handler返回到内核代码

最后，内核再恢复之前被中断的进程。

 

在现代操作系统中，用户应用程序能够拥有和内核一样对虚拟内存系统的机制，主要的好处是提供更大的灵活性和控制权，增强错误处理和恢复能力。这种机制允许应用程序在遇到内存访问错误（如segfault）时，自定义处理逻辑，从而提高应用的健壮性和可靠性。以下是对这种机制的详细解释和它的实际应用，以及与传统内核处理方式的对比。

 

用户空间处理segfault的机制和好处

机制：

1segfault事件传播到用户空间：

当一个segfault（段错误）发生时，操作系统捕获到这个异常。

操作系统将这个异常信息传播到用户空间，通知应用程序。

2upcall到用户空间运行handler：

操作系统通过一种称为upcall的机制，将控制权交给用户空间的异常处理函数（handler）。

这个handler是应用程序预先设置的，用于处理segfault。

3handler调用mprotect修改PTE权限：

在handler中，应用程序可以调用mprotect等系统调用来修改页表项（PTE）的权限，调整内存访问权限。

4handler返回到内核代码：

处理完成后，handler将控制权返回给操作系统内核。

5内核恢复被中断的进程：

操作系统内核恢复之前被中断的进程，继续执行原来的代码。

 

好处

定制化错误处理：应用程序可以定义自己的错误处理逻辑，避免程序崩溃，提高健壮性。例如，可以记录日志、清理资源、尝试恢复等。

更快的响应：在某些情况下，用户空间的处理可能比内核处理更快，因为减少了内核和用户空间之间的上下文切换次数。

灵活性：应用程序可以根据具体情况决定如何处理异常，而不是依赖于内核的默认处理逻辑。

资源管理：应用程序可以在处理异常时执行特定的资源管理操作，如释放内存、关闭文件等。

与传统内核处理segfault的对比

传统内核处理方式

1segfault事件在内核中处理：

当发生segfault时，操作系统内核捕获异常，并在内核中处理。

内核可能会终止进程，生成核心转储（core dump）等。

2内核处理逻辑：

内核处理逻辑是通用的，适用于所有进程，缺乏应用程序特定的处理能力。

3上下文切换：

处理过程中需要多次在用户空间和内核空间之间切换，可能增加开销。

 

当我们执行upcall的时候，upcall会走到设置了handler的用户空间进程中，所以handler与设置了它的应用程序运行在相同的context，相同的Page Table中。所以handler唯一能做的事情就是影响那个应用程序，并不能影响其他的应用程序，因为它不能访问其他应用程序的Page Table，或者切换到其他应用程序的Page Table。所以安全漏洞问题还好。当然，如果handler没有返回，或者做了一些坏事，最终内核还是会杀掉进程。所以唯一可能出错的地方就是进程伤害了自己，但是它不能伤害任何其他进程。

 

**应用**

![img](assets\clip_image006-1729430110986-13.jpg)

上面是一个表，存储着运算结果，要查结果就调用函数f，f(i)即可。

这里的挑战是，表单可能会很大，或许会大过物理内存，这里可以使用论文提到的虚拟内存特性来解决这个挑战。

 

首先，你需要分配一个大的虚拟地址段，但是并不分配任何物理内存到这个虚拟地址段。这里只是从地址空间获取了很大一段地址，并说我将要使用地址空间的这部分来保存表单。

 

但是现在表单中并没有内容，表单只是一段内存地址。如果你现在查找表单的i槽位，会导致Page Fault。所以这里的计划是，在发生Page Fault时，先针对对应的虚拟内存地址分配物理内存Page，之后计算f(i)，并将结果存储于tb[i]（这是存在虚拟内存中的），也就是表单的第i个槽位，最后再恢复程序的运行。

 

这种方式的优势是，如果你需要再次计算f(i)，你不需要在进行任何费时的计算，只需要进行表单查找。即使接下来你要查找表单的i+1槽位，因为一个内存Page可能可以包含多个表单项，这时也不用通过Page Fault来分配物理内存Page。

 

**（对最后一句话的解释：当你访问表单的某个槽位 tb[i] 时，发生页面缺页，操作系统会分配一个物理内存页并映射到对应的虚拟内存地址。一个物理内存页（通常是 4KB\**）可以包含多个表单项（多个 tb[i]）。假设每个表单项占用 4\** 字节，那么一个 4KB 的内存页可以容纳 1024 个表单项。**

**所以，如果你在访问 tb[i] 时发生了页面缺页，操作系统为 tb[i] 所在的虚拟内存地址分配了一个物理内存页，这个页不仅包含 tb[i]\**，还会包含 tb[i+1]、tb[i+2]\** 直到 tb[i+1023]\**。接下来访问 tb[i+1]\** 或 tb[i+2] 等这些表单项时，这些地址已经被映射到了同一个物理内存页，因此不会再次发生页面缺页，也不需要再次分配物理内存页（但是还是要计算，但不会发生缺页了以此就能减少时间）。这样就减少了页面缺页的频率，提升了内存访问的效率。）**

 

不过如果你一直这么做的话，因为表单足够大，你最终还是会消耗掉所有的物理内存。所以Page Fault Handler需要在消耗完所有的内存时，回收一些已经使用过的物理内存Page。当然，你需要修改已经被回收了的物理内存对应的PTE的权限，这样在将来使用对应地址段时，就可以获得Page Fault。所以你需要使用Prot1或者ProtN来减少这些Page的accessbility。

 

栈的大小在大多数情况下是固定的，并在程序启动或线程创建时配置。在Windows上，可以使用 /STACK 链接器选项来设置栈大小。例如：/STACK:reserve[,commit]

在Linux上，可以使用 ulimit -s 命令来设置栈大小，或者在程序中使用 setrlimit 函数。栈是向下生长，而堆是向上生长（从低地址向高地址），栈满了之后就会栈溢出。

栈是为每个线程分配的一块连续的内存区域，主要用于存储函数调用的上下文（如局部变量、函数参数、返回地址等，超出这个大小会引发栈溢出，通常需要在编写程序时避免过深的递归和过多的局部变量，以防止栈溢出问题。）。堆允许程序在运行时根据需要动态分配和释放内存（但会有内存泄露的问题）。这种灵活性使得程序能够处理动态变化的内存需求。堆内存适合存储大小不定的或复杂的数据结构，如链表、树、图等。当需要分配大块内存时，堆比栈更适合。栈的大小有限，不适合存储大型数组或对象。例如，在C++中，使用 new 操作符在堆上分配对象，并使用 delete 释放对象。



Garbage Collector和Garbage Collection都简称为GC，GC是指编程语言替程序员完成内存释放，这样程序员就不用像在C语言中一样调用free来释放内存。

![img](assets\clip_image008-1729430110986-14.jpg)

![img](assets\clip_image010-1729430110986-15.jpg)

什么是copying GC？假设你有一段内存作为heap，应用程序从其中申请内存。你将这段内存分为两个空间，其中一个是from空间，另一个是to空间。当程序刚刚启动的时候，所有的内存都是空闲的，应用程序会从from空间申请内存。假设我们申请了一个类似树的数据结构。树的根节点中包含了一个指针指向另一个对象，这个对象和根节点又都包含了一个指针指向第三个对象，这里构成了一个循环。

![img](assets\clip_image012-1729430110986-16.jpg)

 

或许应用程序在内存中还有其他对象，但是没有别的指针指向这些对象，所以所有仍然在使用的对象都可以从根节点访问到。在某个时间，或许因为之前申请了大量的内存，已经没有内存空间给新对象了，也就是说整个from空间都被使用了。

Copying GC的基本思想是将仍然在使用的对象拷贝到to空间去，具体的流程是从根节点开始拷贝。每一个应用程序都会在一系列的寄存器或者位于stack上的变量中保存所有对象的根节点指针，通常来说会存在多个根节点，但是为了说明的简单，我们假设只有一个根节点。拷贝的流程会从根节点开始向下跟踪，所以最开始将根节点拷贝到了to空间，但是现在根节点中的指针还是指向着之前的对象。

 

之后，GC会扫描根节点对象。因为程序的运行时知道对象的类型是什么，当然也就知道对象中的指针。接下来GC会将根节点对象中指针指向的对象也拷贝到to空间，很明显这些也是还在使用中的对象。当一个对象被拷贝到to空间时，根节点中的指针会被更新到指向拷贝到了to空间的对象。

![img](assets\clip_image014-1729430110986-17.jpg)

 

在之后的过程中，我们需要记住这个对象已经被拷贝过了。所以，我们还会存储一些额外的信息来记住相应的对象已经保存在了to空间，这里会在from空间保留一个forwarding指针。这里将对象从from空间拷贝到to空间的过程称为forward。

![img](assets\clip_image016-1729430110986-18.jpg)

接下来还剩下一个对象，我们将这个对象从from空间拷贝到to空间，这个对象还包含一个指针指向第二个对象。

但是通过查看指针可以看到这个对象已经被拷贝了，并且我们已经知道了这个对象被拷贝到的地址（注，也就是之前在from空间留下的forwarding指针）。所以我们可以直接更新第三个对象的指针到正确的地址。

![img](assets\clip_image018-1729430110986-19.jpg)

 

现在与根节点相关的对象都从from空间移到了to空间，并且所有的指针都被正确的更新了，所以现在我们就完成了GC，from空间的所有对象都可以被丢弃，并且from空间现在变成了空闲区域。

以上就是copying GC的基本思路。论文中讨论的是一种更为复杂的GC算法，它被称为Baker算法，这是一种很老的算法。它的一个优势是它是实时的，这意味着它是一种incremental GC（注，incremental GC是指GC并不是一次做完，而是分批分步骤完成）。在Baker算法中，我们还是有from和to两个空间。假设其中还是包含了上面介绍的几个对象。

 

 

这里的基本思想是，GC的过程没有必要停止程序的运行并将所有的对象都从from空间拷贝到to空间，然后再恢复程序的运行。GC开始之后，唯一必要的事情，就是将根节点拷贝到to空间。所以现在根节点被拷贝了，但是根节点内的指针还是指向位于from空间的对象。根节点只是被拷贝了并没有被扫描，其中的指针还没有被更新。

![img](assets\clip_image020.jpg)

 

如果应用程序调用了new来申请内存，那就再扫描几个对象，并将这些对象从from空间forward到to空间。这很好，因为现在我们将拷贝heap中还在使用的所有对象的过程，拆分成了渐进的步骤。每一次调用new都使得整个拷贝过程向前进一步。

 

 当然应用程序也会使用这里对象所指向的指针。举个例子，现在当根节点需要读出其指向的一个对象时，这个对象仍然在from空间。这是危险的，因为我们不应该跟踪from空间的指针（注，换言之GC时的指针跟踪都应该只在同一个空间中完成）。所以每次获取一个指针指向的对象时（dereference），你需要检查对象是否在在from空间，如果是的话，将其从from空间forward到to空间。所以应用程序允许使用指针，但是编译器需要对每个指针的访问都包上一层检查，这样我们就可以保证在to空间的任何指针指向的是位于to空间的对象。我们需要确保这一点，因为在最后当GC完成了所有对象的跟踪之后，我们会清空from部分并重用这部分内存。

 

 

论文对于这里的方案提出了两个问题：

第一个是每次dereference都需要有以上的额外步骤，每次dereference不再是对于内存地址的单个load或者store指令，而是多个load或者store指令，这增加了应用程序的开销。

 

第二个问题是并不能容易并行运行GC。如果程序运行在多核CPU的机器上，并且你拥有大量的空闲CPU，我们本来可以将GC运行在后台来遍历对象的图关系，并渐进的拷贝对象。但是如果应用程序也在操作对象，那么这里可能会有抢占。应用程序或许在运行dereference检查并拷贝一个对象，而同时GC也在拷贝这个对象。如果我们不够小心的话，我们可能会将对象拷贝两遍，并且最后指针指向的不是正确的位置。所以这里存在GC和应用程序race condition的可能。

 

所以可以用论文中提到的虚拟内存特性解决：

这里的基本思想是将heap内存中from和to空间，再做一次划分，每一个部分包含scanned，unscanned两个区域。在程序启动，或者刚刚完成了from和to空间的切换时，整个空间都是unscanned，因为其中还没有任何对象。之后的过程与前面描述的相同，在开始GC时，我们将根节点对象拷贝到to空间，但是根节点中的指针还是指向了位于from空间的对象。现在unscanned区域包括了所有的对象（注，现在只有根节点），我们会将unscanned区域的权限设置为None。这意味着，当开始GC之后，应用程序第一次使用根节点，它会得到Page Fault，因为这部分内存的权限为None。

![img](assets\clip_image002-1729430202988-30.jpg)

在Page Fault Handler中，GC需要扫描位于内存Page中所有的对象，然后将这些对象所指向的其他对象从from空间forward到to空间。所以，在GC最开始的时候，我们将根节点拷贝过来了；之后在Page Fault Handler中通过扫描，将根节点指向的对象也都拷贝过来了。在我们的例子中根节点指向的只有两个对象，这两个对象会被拷贝到unscanned区域中，而根节点会被标记成scanned。在我们扫描完一个内存Page中的对象时，我们可以通过Unprot（注，详见17.1）恢复对应内存Page的权限。

(tospace中含有unscaned区域，unscaned和复制（forwarding）又是两个东西，unscaned就是“还没有扫描其指针指向对象”的意思

像上图，flip后把根结点root复制到tospace，此时root还是unscaned，当要用到根结点指向的那个对象后（比如对象1），由于其不在tosapce，所以会pgfalut，在handler中将fromspace中的root节点指向的对象（在这里是对象1和对象2）复制到tospace中的unscaned区域，此时root就可以标记为scanned了。（因为我们已经扫描完了root节点所指向的对象）)

之后，应用程序就可以访问特定的对象，因为我们将对象中的指针转换成了可以安全暴露给应用程序的指针（注，因为这些指针现在指向了位于to空间的对象），所以应用程序可以访问这些指针。当然这些指针对应的对象中还没有被扫描。如果dereference这些指针，我们会再次得到Page Fault，之后我们会继续扫描。

这种方案的好处是，它仍然是递增的GC，因为每次只需要做一小部分GC的工作。除此之外，它还有额外的优势：现在不需要对指针做额外的检查了（注，也就是不需要查看指针是不是指向from空间，如果是的话，将其forward到to空间）。或者说指针检查还在，只是现在通过虚拟内存相关的硬件来完成了。

论文中提到使用虚拟内存的另一个好处是，它简化了GC的并发。GC现在可以遍历未被扫描的内存Page，并且一次扫描一个Page，同时可以确保应用程序不能访问这个内存Page，因为对于应用程序来说，未被扫描的内存Page权限为None。虚拟内存硬件引入了这种显式的同步机制，或者说对于抢占的保护。

现在只有GC可以访问未被扫描的内存Page，而应用程序不能访问。所以这里提供了自动的并发，应用程序可以运行并完成它的工作，GC也可以完成自己的工作，它们不会互相得罪，因为一旦应用程序访问了一个未被扫描的Page，它就会得到一个Page Fault。而GC也永远不会访问扫描过的Page，所以也永远不会干扰到应用程序。所以这里以近乎零成本获取到了并发性。

但是实际上有个麻烦的问题。回到我们之前那张图，我们在heap中有from空间，to空间。在to空间中又分为了unscanned和scanned区域，对于应用程序来说，unscanned区域中的Page权限为None。

 

这就引出了另一个问题，GC怎么能访问这个区域的内存Page？因为对于应用程序来说，这些Page是inaccessible。

这里的技巧是使用map2（注，详见17.1）。这里我们会将同一个物理内存映射两次，第一次是我们之前介绍的方式，也就是为应用程序进行映射，第二次专门为GC映射。在GC的视角中，我们仍然有from和to空间。在to空间的unscanned区域中，Page具有读写权限。

![img](assets\clip_image004-1729430202988-31.jpg)

所以GC可以遍历这些内存Page，读取内容并forward必要的对象。这里使用了map2将物理内存映射到应用程序地址空间中两次的能力，其中每次映射都有不同的权限，这样这里的场景才能工作。

 

## lab内容

argaddr(0,&aa),就是获取**系统调用**参数0传给aa，argint也一样,argfd要3个参数，多一个参数是指明要哪个file。

r-stval()存储了引发页面错误的虚拟地址。

函数调用顺序要弄清楚！函数a调用了函数b，那么函数b要在a前面声明或者定义先！

分清楚&和&&，前者是位运算，后者是逻辑与

单个 &（按位与运算符）

功能：按**位与运算符逐位比较两个操作数的二进制**表示，如果对应位都是 1，则结果为 1，否则为 0。

使用场景：主要用于位操作。

示例：

int a = 5;  // 5 的二进制表示为 0101

int b = 3;  // 3 的二进制表示为 0011

int c = a & b; // 结果为 0001， 即 c = 1

 

双 &&（逻辑与运算符）

功能：**逻辑与运算符用于判断两个条件是否同时为真**。只有在两个操作数都为真时，结果才为真；否则为假。

使用场景：主要用于逻辑判断和条件控制。

短路特性：当第一个操作数为假时，第二个操作数不会被计算。

示例：

int x = 10;

int y = 20;

if (x > 5 && y < 30) {

  // 这段代码会被执行，因为 x > 5 为真且 y < 30 为真

}