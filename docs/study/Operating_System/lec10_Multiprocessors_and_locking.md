## 课前内容

获得锁就可以运行自己的代码了。

访问共享资源的代码段，我们称之为临界区Critical Section，而多个执行线程同时进入临界区并尝试更新共享数据结构的情况，我们称之为竞争条件Race Condition。多个执行线程可以同时进入临界区，避免产生竞争条件，最终能够产生确定的输出。为此，设计者们提供了很多并发控制Concurrency Control技术，或者同步工具Synchronization Tools。

常用的同步工具有：锁Lock，条件变量Conditional Variable，信号量Semaphore等。

这些同步工具，保证了临界区中工作的原子性atomic，换句话说就是All-or-Nothing。

一次只有一个CPU能够获得锁，锁本质上使并发操作变得串行化/序列化Serialized，当然也会有多个CPU争夺Content同一把锁。锁的作用：

1使用锁有助于避免更新的丢失。（Locks help avoiding lost updates.）

2使用锁使多步操作变为原子性的操作。（Locks make multi-step operations atomic.）

3使用锁有助于维持一些规则或特性的不变性。（Locks help maintain invariant.）

 

 

有两种用于处理操作系统临界区问题的常用方法：抢占式内核Preemptive Kernels和非抢占式内核Nonpreemptive Kernels。抢占式内核允许在内核空间下运行的进程被抢占，不断通过时钟中断一个线程，运行其它线程；而非抢占式内核则不允许，进程会一直运行直到退出内核空间、阻塞或自愿放弃CPU。非抢占式内核基本不会导致竞争条件，因为任一时刻只有一个进程在内核空间下运行；而抢占式内核则需要仔细设计，以防止竞争条件出现，尤其是对称多处理器体系结构。但我们更倾向于使用抢占式内核，因为这种内核响应更快，进程不会在内核中运行任意长的时间，还允许实时进程抢占在内核空间下运行的其它进程。

 

现代只需要很少的硬件支持，实现锁就会容易很多。（因为基于软件的解决方案并不保证在现代计算机体系结构上能够正确工作）下面介绍一系列的硬件方法，其中涉及到的硬件指令是原子的，利用这些硬件支持我们能够实现出各种同步工具，包括锁。

1

int TestAndSet(int *old_ptr, int new){

 int old = *old_ptr; // 获取旧的值

 *old_ptr = new;   // 存储新的值

 return old;     // 返回旧的值

}这个特殊硬件指令，叫做测试并设置test-and-set，其中的逻辑，可以用C代码展示如上，但要注意，这个硬件指令是原子性的，用c代码只是为了展现逻辑。

如果当前线程不能获取该锁，它就在原地上等待，不断消耗CPU周期，这种锁叫做自旋锁Spinning Lock。这是一个简单的解决方案，但是不适合于采用非抢占式内核的单处理器系统，因为一个自旋的线程永远不会放弃CPU。

![img](assets\clip_image002-1729267823437-1.jpg)

这段代码也不够严谨，但要能理解它的设计思想。（解决方案满足互斥和进步和有限等待)可以验证，希望进入临界区的线程，现在至多只需要等待n-1次。

2

int CompareAndSwap(int *ptr, int expected, int new){

 int actual = *ptr;

 if(actual == expected)

  *ptr = new;

 return actual;

}比较并交换compare-and-swap。思路就是检测ptr指向的值是否和expected相等。如果是，就更新ptr的值为new，否则什么也不更新。无论如何，最后都返回该内存地址的实际值actual。在上面中，把用test-and-set的地方改为用compare-and-swap来实现锁即可。

![img](assets\clip_image004-1729267823437-2.jpg)

3

int FetchAndAdd(int *ptr){

 int old = *ptr;

 *ptr = old + 1;

 return old;

}与test-and-set类似，但可以用它来实现一个ticket锁。

ticket即排队号，turn表示当前排到哪一号了，lock 函数通过 FetchAndAdd 获取当前的 ticket 值（即排队号），然后 ticket 自增。线程将获得的排队号保存在 myturn 变量中。

线程 A 运行并调用 lock(&lock_t)：

它获得 ticket 为 0 的值，将 ticket 增加到 1。myturn 为 0，因为 lock->turn 也是 0，所以线程 A 进入临界区。

同时，线程 B 也尝试访问打印机，调用 lock(&lock_t)：它获得 ticket 为 1 的值，将 ticket 增加到 2。myturn 为 1，但因为 lock->turn 仍为 0（线程 A 正在临界区），线程 B 必须等待。

线程 A 完成打印任务，调用 unlock(&lock_t)，这将 turn 增加到 1。

这时，线程 B 检测到 lock->turn 等于其 myturn（1），因此进入临界区。

4

int LoadLinked(int *ptr){

 return *ptr;

}

int StoreConditional(int *ptr, int value){

 if(在上一次加载ptr之后，期间没有对ptr的更新){

  *ptr = value;

  return 1; // 成功

 }else{

  return 0; // 失败

 }

}链接加载Load-Linked和条件式存储Store-Conditional指令

它们与ld，sd指令差不多，实现锁的代码如下

void lock(lock_t *lock){

 while(LoadLinked(&lock->flag) || !StoreConditional(&lock->flag, 1))

  ;

}Store-Conditional何时会失败？考虑以下情况，一个线程调用lock，执行了Load-Linked并返回0，但在执行Store-Conditional之前，发生了时钟中断，另一个线程也调用lock，同样执行Load-Linked，因为锁还没有被获取，所以同样返回0。两个线程都执行了Load-Linked，而且都将要执行Store-Conditional，但只有一个线程会成功更新flag为1并获得锁，第二个线程会失败，因为在这期间flag已经被更新了，所以它需要重新尝试获取锁。

 

5

计算机体系结构将确定它为应用程序提供什么样的内存保证，这被称为内存模型Memroy Model。一般来说，内存模型可以分为两类：

严格一致性/强一致性（Strongly Ordered）：一个CPU对内存做了某些修改，其它CPU马上就能看到这项更新。

松散一致性/弱一致性（Weakly Ordered）：一个CPU对内存做了某些修改，但其它CPU不能马上，而可能在稍后才会看见这项更新。

由于内存模型的类型和CPU密切相关，在一个共享RAM的多处理器系统中，我们的内核不能对这些修改的可见性做任何假设。为此，计算机体系结构提供了一种指令，它可以强制内存的更新对所有CPU可见，这种指令就是内存屏障Memory Barriers（或Memory Fences）。当执行内存屏障指令时，系统确保，在内存屏障之前所有的load和store，都会在内存屏障之后的load或store执行前完成。因此，即使指令被重新排序，内存屏障确保了，位于它之前的存储操作已经在内存中完成，因此在内存屏障之后，这些存储操作对所有处理器是可见的。

 

6

有另一种原子的硬件支持，不过这次是变量类型，我们称为原子变量Atomic Variables。

你可能还记得我们在一开始讨论竞争条件或临界区问题时举的例子，问题的产生就在于count变量的更新，因为count不是原子性地更新，这才导致了后续的问题。而原子变量可以提供互斥机制，保证在更新该变量时不会出现竞争条件。

很多支持原子变量的操作系统都提供特殊的原子变量数据类型，以及访问和操作它们的函数。这些函数经常用你已经熟知的compare-and-swap来实现，下面是其中一个例子。

```C 
void increment(atomic int *v)

{

 int temp;

 do {

  temp = *v;

 }

 while (temp != compare and swap(v, temp, temp+1));

}
```

值得一提的是，尽管原子变量提供原子性的更新，从而避免了在更新变量时出现竞争条件，但是却无法避免其它竞争条件的出现。还是回到我们一开始举的有界缓冲区的例子，现在我们可以用一个原子变量代替count，count的更新就是原子性的。但是对于生产者和消费者进程的while循环，其条件判断也是取决于count的。考虑一种情况，当前缓冲区为空，因此有两个消费者进程会不断循环，等待count>0。如果现在有生产者往缓冲区中写入一项内容，那么count=1，因此两个消费者进程都有机会跳出while循环，并同时进入临界区中，但我们的缓冲区中只有1项内容可读，因此错误就会发生。

以上是多种硬件支持。

 

对于锁我们一般提供两个接口，一个是acquire用于获取锁，一个是release用于释放锁。

自旋锁不满足有限等待的要求，可能会导致某些线程饥饿。然后关注性能，自旋锁的主要缺点是，它会忙等，这种忙等会持续消耗CPU资源，因为它要不停地旋转以等待锁可用。不过，在多CPU上，尤其是当线程数大于CPU数时，自旋锁的性能表现不错。假设线程A在CPU1上，线程B在CPU2上，都竞争同一个锁。A占有锁时，B会在CPU2上自旋，而临界区一般很短，所以B很快就获得锁。因此，自旋等待其它CPU上的锁时，不会浪费很多CPU周期。另外，线程在等待锁时，没有上下文切换（尤其是上下文切换的开销可能比较大），因此如果临界区较短，使用自旋锁也是一个不错的方案。

上下文切换是指在操作系统中，CPU从执行一个进程或线程转换到执行另一个进程或线程的过程。

**如果中断处理程序需要持有某一把自旋锁，那么每个****CPU****在持有这把自旋锁时，一定要保持中断关闭。**

xv6的解决方式更加保守一些：只要CPU试图获取任何自旋锁，那么该CPU总是会关闭中断。所以，你在前面xv6的acquire实现中，可以看到进入该函数的第一件事就是关闭中断。中断仍然可以在其它CPU上产生，所以一个中断处理程序的acquire可以等待别的线程释放相应的锁，只是该线程将在不同的CPU上运行。

以上讨论的互斥锁均为自旋锁。

 

如果一把锁在长时间内都被其它进程持有，那么尝试获取该锁的其它线程不必占用大量的CPU周期，而是以一种睡眠的方式主动放弃CPU，在稍后的某个时间再被重新唤醒执行。

遗憾的是，自旋锁并不支持这种特性。首先，自旋锁会浪费大量的CPU周期；其次，已经持有自旋锁的进程不应该主动放弃CPU，这可能会导致死锁，因为acquire()是原子操作（中断关闭），则当存在第二个线程尝试获取已被第一个进程持有的自旋锁时，会导致无限循环并且无法调度，所以应当遵循进程持有自旋锁时中断应保持关闭这一原则。为此，我们重新设计另一种类型的锁。这种类型的锁，会在acquire需要自旋等待时让出CPU；同时，在持有这种锁时，允许主动放弃CPU和开放中断。

这种类型的锁，我们称为睡眠锁Sleep Lock。简单实现方式如下

```C 
void lock(){
  while(TestAndSet(&flag, 1) == 1)

  yield(); // 主动放弃CPU

}
```



yield让进程的状态从RUNNING变为RUNNABLE，并让调度器寻找其它状态为RUNNABLE的进程允许，让出CPU的本质就是进程取消调度deschedule了自己。但是，这个解决方案还不够完善。回忆一下我们临界区问题的三个要求，对于有限等待条件，该解决方案还不能明确地支持它，原因是该方案还存在很多偶然性，例如调度程序进行调度的合理性。无论是一直自旋，还是立刻主动让出CPU，都可能造成浪费，也不能防止饥饿。为此需要操作系统提供更多的支持，使用队列来保存等待锁的进程是常用的解决方案，决定锁释放时，谁能抢到锁。



![img](assets\clip_image002-1729267932730-5.jpg)

这段代码展示的是一个使用两层锁结构（一个guard锁和一个flag锁）来管理对一个临界区的访问的锁实现。这种设计同时使用了一个队列来管理等待访问该临界区的线程。这里的锁实现旨在确保在多线程环境中线程安全地访问共享资源。用一个简单的例子来解释这段代码的工作原理。

\### 场景描述：假设有一个共享打印机，多个员工（线程）需要使用这个打印机。为了公平和有序地使用这个打印机，我们需要确保同一时间只有一个员工能打印。

\### 锁的组成

\- **guard锁**：guard 锁确保在任何时刻只有一个线程可以修改 flag 锁的状态和管理等待队列。它用来保护flag锁的状态，确保在检查或修改flag锁的时候不会有其他线程同时进行这些操作。就是避免队列中其它人插队。

\- **flag锁**：用来表示是否有线程正在使用打印机。

\- **队列**：用来存放等待使用打印机的线程的标识（或者说，等待使用该资源的线程）。

\### 锁的操作

\- **初始化（`lock_init`）**：打印机刚开始是空闲的，所以`flag`设置为0（无人使用）。`guard`也是0，表示guard锁是空闲的。队列被初始化，准备存放可能需要等待的员工。

\- **尝试获取锁（`lock`）**：

1. **获取guard锁**：每个想要使用打印机的员工首先必须获取`guard`锁。如果`guard`锁已被其他员工持有，则当前员工会等待（自旋），直到`guard`锁变为可用。
2. **检查flag锁**：一旦拿到`guard`锁，员工检查`flag`锁。如果`flag`为0（无人使用打印机），则该员工将`flag`设置为1（表示打印机正在使用中），并释放`guard`锁。
3. **等待**：如果`flag`已经是1（打印机被占用），员工会把自己的ID加入等待队列，并在释放`guard`锁后进入休眠状态（`park`），等待被唤醒。

\- **释放锁（`unlock`）**：

1. **获取guard锁**：完成打印任务的员工必须再次获取`guard`锁。
2. **检查等待队列**：如果没有其他员工在等待队列中等待，则将`flag`重置为0（表示打印机空闲）。如果队列中有等待的员工，选择一个（通常是队列前端的）并唤醒他（`unpark`），传递`flag`锁的控制权给他。
3. **释放guard锁**：操作完成后，释放`guard`锁。

\### 例子

假设Alice和Bob都想打印文档。Alice先到，获取了`guard`锁，然后设置`flag`为1，并开始打印。此时Bob到达，也尝试获取`guard`锁，Alice打印时Bob只能自旋等待。当Alice完成打印，她尝试解锁，此时发现Bob在等待，于是她唤醒Bob并将打印机的控制权转交给他。

这个锁实现通过两层锁（一个快速检查的`guard`锁和一个实际控制的`flag`锁）以及一个队列来有效管理对共享资源的访问，既保证了使用的公平性也提高了效率。

最后，这个解决方案还有一个潜在的竞争条件。例如，Thread1首先进入，成功获取了 flag 锁（flag=1），进入临界区。Thread2随后尝试获取锁，但由于Thread1持有 flag 锁，Thread2进入 lock() 函数的 else 分支：Thread2将自己添加到等待队列；Thread2准备通过调用 park() 进入等待状态。就在Thread2执行 park() 之前，操作系统进行了上下文切换，切换回了Thread1。Thread1完成其任务，调用 unlock() 函数：发现队列非空，尝试唤醒队列中的线程（此时为Thread2）。调用 unpark(Thread2)，但此时Thread2尚未实际执行 park()。Thread1退出，系统切换回Thread2。Thread2现在执行 park() 并实际进入休眠状态。由于Thread2已被尝试唤醒，但实际上还没有开始休眠，unpark() 的调用无效。Thread2实际进入休眠后，没有其他线程能唤醒它，因为唤醒信号已经被发送且丢失。如果此后其他线程（比如Thread3）尝试获取这个锁，它们也会因为Thread2持有 flag 锁并且实际上处于休眠状态而无法继续，导致更多线程进入等待状态。这种情况有时也称为唤醒/等待竞争wakeup/waiting race。

解决方法：Solaris增加了第三个系统调用setpark来解决这种情况，一个线程通过调用setpark表明自己马上要park，此时如果刚好另一个线程被调度，并且调用了unpark，那么后续的park调用就会直接返回，而不是一直睡眠。或者，另外一种方案是把guard传入内核，内核可以采取一些预防措施，保证原子地释放锁，并把运行进程移出队列。

**不能在自旋锁保护的临界区中使用睡眠锁，但是可以在睡眠锁保护的临界区中使用自旋锁。**

 

睡眠锁的优点显然是避免使用自旋锁时，带来的大量CPU周期的浪费；其缺点是，来回地切换进程会导致较高的上下文切换开销。根据两种锁的特点，在临界区较短的时候，使用自旋锁比较合适；而在临界区比较长的时候，就应该使用睡眠锁。也可以将两种锁结合，称为两阶段锁，第一阶段先自旋一段时间，希望可以获取锁，但如果没有获得，那么在第二阶段调用者会睡眠，直到锁可用。Linux就采用了这种锁，不过只自旋一次，更常见的方式是在循环中自旋固定的次数，然后再睡眠。

 

使用了锁，这又使得多CPU的性能优势衰减，经常出现多个进程争夺锁的情况，我们称这种现象为锁的争夺Contention。减少锁的争夺是提高多线程程序性能和响应性的关键。锁争用通常会导致线程等待和上下文切换，这些都会消耗宝贵的系统资源并降低应用程序的效率。以下是一些有效的策略，可以帮助减少锁的争用：

**### 1.** **细粒度锁**

将大锁分解为几个小锁，每个锁保护资源的一个更小的部分。这样，即使多个线程需要同时访问共享资源，它们也可能争夺不同的锁，从而减少了锁的争用。（比如上面的睡眠锁中的flag是大锁，即这个锁控制着是否互斥访问临界资源，自旋锁guard是小锁即控制着各种进程互斥获取flag。若guard也是睡眠锁，在更改flag时若被中断打断很有可能会造成前面提到的死锁。）

**### 2.** **锁分离**

尝试将不同种类的操作分别用不同的锁来控制。例如，如果有两个独立的数据结构需要保护，就为每个数据结构使用单独的锁，而不是一个共同的锁。

**### 3.** **读写锁**

如果你的应用主要是读取数据，而写入操作比较少，使用读写锁（shared-exclusive lock）是一个好选择。读写锁允许多个读者同时读取数据，但写操作需要独占访问。

\### 4. 无锁编程

使用原子操作和无锁数据结构可以完全避免锁的使用。这种方式通常依赖于复杂的算法来保证数据一致性，但在高度并发的环境中，它可以显著提高性能。

\### 5. 锁升级和降级

在某些情况下，可以根据需要动态地升级或降级锁的严格程度。例如，首先尝试使用更宽松的锁（如共享锁），如果后续操作需要更严格的控制，则升级为排他锁。

\### 6. 避免持锁时间过长

在持有锁的同时尽量不要进行长时间的操作，比如网络调用或者磁盘I/O。这样可以减少其他线程等待锁的时间。

\### 7. 使用条件变量

条件变量可以用来阻塞一个线程直到某个特定条件为真。与不断地轮询锁状态相比，这可以显著减少CPU的使用，并减少锁的争用。

\### 8. 优化锁的顺序

在多个锁被一个以上的线程需要时，始终以相同的顺序获取锁，可以避免死锁和减少锁的等待时间。

\### 9. 软件事务内存 (STM)

STM 提供了一种管理共享数据的替代方法，允许代码块在看似无锁的环境中执行，而冲突解决和数据一致性由 STM 系统自动处理。

通过实现这些策略，可以有效地减少锁的争夺，提高多线程程序的性能。在实际应用中，选择哪种方法取决于具体的问题、数据访问模式和性能需求。

 

前面已经提到了两种可能引起死锁的情况：

中断处理程序尝试获取线程已经持有的自旋锁。

持有自旋锁的进程主动放弃CPU。

现在我们再补充一种，这种死锁的出现和上锁的顺序Lock Ordering有关。一个最简单的例子，进程1获取锁的顺序是先A后B，进程2则是先B后A。如果进程1获得A的同时，进程2也获得了B，那么死锁就发生了。避免这种死锁的解决方案看上去也很简单，只需要规定一个全局的上锁顺序即可。规定全局的上锁顺序，意味着锁实际上是每个函数规范的一部分：调用者必须以一种规定的顺序调用函数，以遵循获取锁的顺序。但实际上遵循一个全局的上锁顺序是十分困难的。



## lab内容

COW fork

由于增加减少引用是原子性的，所以要加锁

引用计数数组中：

----数组的容量

将最大物理地址PHYSTOP右移12位(相当于除以4096，即一个物理页面的大小)即可，即数组的容量为PHYSTOP >> 12。（也即PHYSTOP/PGSIZE，想一下内存那张图，被分成了很多块，总共有这么多块）

注： 实际上物理地址KERNBASE以下映射的是外设，不涉及COW机制，可以将数组容量缩小至(PHYSTOP-KERNBASE)>>12节省空间，我这里没有进行缩小。

数组中每个元素需要记录对应物理页面的引用数量，xv6最多可分配的进程数NPROC为64，所以使用8 bit的uint8数据类型存储每个物理页面的引用数量即可。

又要引入锁结构体，又要加个数组，所以就把他们封装成一个结构体即可。

 

lab步骤：

1 利用RSW位去标记它是否为cow页（基础）

  故在risc.h中添加#define PTE_COW (1L << 8)

 

2 添加引用计数，每个页面都可以创造个计数，那么就用数组，数组的下标就表示了当前是哪一页，value 值代表引用数。

  2.1 那数组容量是多少？可以用最大物理地址除以4096即一个页面的大小(PGSIZE),可得数组容量

  2.2 增减计数的时候，要考虑到会不会被其它线程篡改，所以要加上锁，仿照别的增加自旋锁结构体即可

```C 
 struct pagerefcnt {

​    struct spinlock lock;

​    uint8 refcount[PHYSTOP / PGSIZE];

  } ref;
```



 

  2.3 增减计数用一个函数去做，因为要把锁给用上，别忘了在defs.h中声明这个函数

 

3 修改kalloc，根据hint，分配一个新页面的时候，要把那个页面的引用计数初始化为1，别忘了锁

 

4 修改kfree，根据hint，引用计数为0才放回freelist中，否则直接返回。故可以写一个if语句，如果有人调用了kfree，那么—计数（要先自减），如果计数还是大于0，就直接return，否则按照原来的kfree走

 

5 使用锁，就得对锁初始化，所以在kinit中对锁初始化，接下来观察到freerange函数，它会调用kfree，初始就调用kfree会让计数小于0这是不对的，所以要在freerange中把每个页面的计数设置为1后，再调用kfree就能把计数变成0，完成了初始化。

 

6 根据hint，修改uvmcopy，这个函数的功能是尝试在操作系统内核中复制一个虚拟内存空间到另一个，原来是立刻memmove，现在就把所有要fork的页面的权限给改一下，即改变pte中的flags（这两个都要写出来，而不是只改变pte，方便以后查flags），之后不立刻kalloc（注释掉）

 

7 不立刻kalloc，那么在用到新页面（即cow页面）的时候就会触发page fault。①在用户态访问cow页面会由于缺页发生page fault，引发trap，流程是uservec→usertrap→usertrapret→userret （在lec06），在usertrap中处理，即承认这个pf并作出行动。

②内核缓存复制到用户空间(如read系统调用)会在copy_out中写入cow页面引起page fault。

大致处理思路为：

----判断虚拟地址的合理性

----将虚拟地址对应的pte映射到新的物理内存

----取消原物理地址的映射(减少引用计数)

 

8 在usertrap中，添加else分支，判断条件是pagefault，对应的scause为15，按照处理思路一步步来。

   8.1 需判断虚拟地址的合法性，即判断pte中的flags是否有cow，没有就得杀掉进程。那么就得先获取虚拟地址，按照上个lab的思想作参考，用stval寄存器来获取va，之后获取这个va对应的pte（用walk函数，注意要在defs.h中声明），检查flags，若没有就得杀掉进程。

   8.2 若有对应的flag。参考上一个lab，先向下取整va，之后真正的为cow这个页面分配内存，注意的是，此时的新页面ka的flags中，cow这个flag要为0（因为新页面肯定不是cow页了），之后取得那个va对应的物理地址，把物理地址pa的内容复制到ka中，并且取消原来的映射，实现新的映射（新的映射中要设W权限）。

 

9 copyout同理，在做之前需检查地址有效性：if(dstva > MAXVA - len) return -1; 确保目标地址加上长度不会溢出。

 

在操作系统的内存管理中，当处理与页相关的操作（如内存映射、地址翻译等）时，计算“下界”而不是“上界”是因为你通常需要找到包含给定虚拟地址的那个页面的起始地址。这是因为内存页是从它们的起始地址开始定义的，每个页面具有固定的大小（如4KB），并从这个基点向上扩展到下一个页面的开始。

 

 